{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers.modeling_utils import (WEIGHTS_NAME, PretrainedConfig, PreTrainedModel,\n",
    "                             SequenceSummary, PoolerAnswerClass, PoolerEndLogits, PoolerStartLogits)\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification, XLNetPreTrainedModel, XLNetModel\n",
    "from torch.nn import CrossEntropyLoss, BCEWithLogitsLoss\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from XLNet import XLNetForMultiSequenceClassification\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import re\n",
    "from utils import *\n",
    "from tqdm.notebook import tqdm\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_MRR(Dataset):\n",
    "    def __init__(self, mode, tokenizer):\n",
    "        assert mode in [\"data/RTE5_test\"]\n",
    "        self.mode = mode\n",
    "        self.df = pd.read_csv(mode + \".tsv\", sep=\"\\t\").fillna(\"\")\n",
    "        self.len = len(self.df)\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        text_a, text_b, text_eval, label = self.df.iloc[idx, :].values\n",
    "        label_tensor = torch.tensor(label)\n",
    "            \n",
    "        inputs = tokenizer.encode_plus(text_a, text_b, return_tensors='pt', add_special_tokens=True)\n",
    "        tokens_tensor = inputs['input_ids']\n",
    "        segments_tensor = inputs['token_type_ids']\n",
    "        masks_tensor = inputs['attention_mask']\n",
    "        \n",
    "        return (tokens_tensor, segments_tensor, masks_tensor, label_tensor, text_a, text_b, text_eval)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset_MRR(\"data/RTE5_test\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def create_mini_batch(samples):\n",
    "    tokens_tensors = [s[0] for s in samples]\n",
    "    segments_tensors = [s[1] for s in samples]\n",
    "    masks_tensors = [s[2] for s in samples]\n",
    "    text_a = [s[4] for s in samples]\n",
    "    text_b = [s[5] for s in samples]\n",
    "    text_eval = [s[6] for s in samples]\n",
    "    \n",
    "    if samples[0][3] is not None:\n",
    "        label_ids = torch.stack([s[3] for s in samples])\n",
    "    else:\n",
    "        label_ids = None\n",
    "    \n",
    "    tokens_tensors = pad_sequence(tokens_tensors, \n",
    "                                  batch_first=True)\n",
    "    segments_tensors = pad_sequence(segments_tensors, \n",
    "                                    batch_first=True)\n",
    "    masks_tensors = pad_sequence(masks_tensors, \n",
    "                                    batch_first=True)\n",
    "    \n",
    "    \n",
    "    return tokens_tensors.squeeze(1), segments_tensors.squeeze(1), masks_tensors.squeeze(1), label_ids, text_a, text_b, text_eval\n",
    "\n",
    "\n",
    "# 初始化回傳訓練樣本的 DataLoader\n",
    "# 利用 `collate_fn` 將 list of samples 合併成一個 mini-batch \n",
    "BATCH_SIZE = 1\n",
    "testloader = DataLoader(dataset, batch_size=1, collate_fn=create_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(model, dataloader, tokenizer, unique=False, in_un=False):\n",
    "    total = len(dataloader)\n",
    "    entail_total = 0\n",
    "    entail_total_len = 0\n",
    "    neutral_total = 0\n",
    "    neutral_total_len = 0\n",
    "    contradict_total = 0\n",
    "    contradict_total_len = 0\n",
    "    \n",
    "    entail_correct = 0\n",
    "    entail_correct_len = 0\n",
    "    neutral_correct = 0\n",
    "    neutral_correct_len = 0\n",
    "    contradict_correct = 0\n",
    "    contradict_correct_len = 0\n",
    "    \n",
    "    entail_MRR_c = 0.\n",
    "    neutral_MRR_c = 0.\n",
    "    contradict_MRR_c = 0.\n",
    "    \n",
    "    entail_MRR_inc = 0.\n",
    "    neutral_MRR_inc = 0.\n",
    "    contradict_MRR_inc = 0.\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data_iterator = tqdm(dataloader, desc='Iteration')\n",
    "        for data in data_iterator:\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "            # predict\n",
    "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            sentence_a = data[4][0]\n",
    "            sentence_b = data[5][0]\n",
    "            eval_sentence = data[6][0]\n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors)\n",
    "            logits = outputs[0]\n",
    "            _, pred = torch.max(logits.data, 1)\n",
    "            \n",
    "            # divide 3 class\n",
    "            label = data[3]\n",
    "            MRR, length = explainability_compare(model,\n",
    "                                                 tokenizer,\n",
    "                                                 sentence_a,\n",
    "                                                 sentence_b,\n",
    "                                                 eval_sentence,\n",
    "                                                 unique=unique,\n",
    "                                                 in_un=in_un\n",
    "                                                )\n",
    "\n",
    "            if label == torch.tensor([0]):\n",
    "                entail_total += 1\n",
    "                entail_total_len += length\n",
    "                if pred == label:\n",
    "                    entail_correct += 1\n",
    "                    entail_correct_len += length\n",
    "                    entail_MRR_c += MRR\n",
    "                else:\n",
    "                    entail_MRR_inc += MRR\n",
    "            elif label == torch.tensor([1]):\n",
    "                neutral_total += 1\n",
    "                neutral_total_len += length\n",
    "                if pred == label:\n",
    "                    neutral_correct += 1\n",
    "                    neutral_correct_len += length\n",
    "                    neutral_MRR_c += MRR\n",
    "                else:\n",
    "                    neutral_MRR_inc += MRR\n",
    "            else:\n",
    "                contradict_total += 1\n",
    "                contradict_total_len += length\n",
    "                if pred == label:\n",
    "                    contradict_correct += 1\n",
    "                    contradict_correct_len += length\n",
    "                    contradict_MRR_c += MRR\n",
    "                else:\n",
    "                    contradict_MRR_inc += MRR\n",
    "    if contradict_correct_len == 0:\n",
    "        contradict_correct += 1\n",
    "        \n",
    "                    \n",
    "    \n",
    "    return {\n",
    "        'total':total,\n",
    "        'total_MRR':round((entail_MRR_c+entail_MRR_inc+\n",
    "                           neutral_MRR_c+neutral_MRR_inc+\n",
    "                           contradict_MRR_c+contradict_MRR_inc)/total, 4),\n",
    "        'total_acc':round((entail_correct+neutral_correct+contradict_correct)/total, 2),\n",
    "        'total_mean_len':round((entail_total_len+neutral_total_len+contradict_total_len)/total, 1),\n",
    "        'entail_total':entail_total,\n",
    "        'entail_acc':round(entail_correct/entail_total, 2),\n",
    "        'entail_mean_len':round(entail_total_len/entail_total, 1),\n",
    "        'entail_MRR':round((entail_MRR_c+entail_MRR_inc)/entail_total, 4),\n",
    "        'entail_correct':entail_correct,\n",
    "        'entail_correct_mean_len':round(entail_correct_len/entail_correct, 1),\n",
    "        'entail_MRR_c':round(entail_MRR_c/entail_correct, 4),\n",
    "        'entail_incorrect':entail_total-entail_correct,\n",
    "        'entail_incorrect_mean_len':round((entail_total_len-entail_correct_len)/(entail_total-entail_correct), 2),\n",
    "        'entail_MRR_inc':round(entail_MRR_inc/(entail_total-entail_correct), 4),\n",
    "        'neutral_total':neutral_total,\n",
    "        'neutral_acc':round(neutral_correct/neutral_total, 2),\n",
    "        'neutral_mean_len':round(neutral_total_len/neutral_total, 1),\n",
    "        'neutral_MRR':round((neutral_MRR_c+neutral_MRR_inc)/neutral_total, 4),\n",
    "        'neutral_correct':neutral_correct,\n",
    "        'neutral_correct_mean_len':round(neutral_correct_len/neutral_correct, 1),\n",
    "        'neutral_MRR_c':round(neutral_MRR_c/neutral_correct, 4),\n",
    "        'neutral_incorrect':neutral_total-neutral_correct,\n",
    "        'neutral_incorrect_mean_len':round((neutral_total_len-neutral_correct_len)/(neutral_total-neutral_correct), 2),\n",
    "        'neutral_MRR_inc':round(neutral_MRR_inc/(neutral_total-neutral_correct), 4),\n",
    "        'contradict_total':contradict_total,\n",
    "        'contradict_acc':round(contradict_correct/contradict_total, 2),\n",
    "        'contradict_mean_len':round(contradict_total_len/contradict_total, 1),\n",
    "        'contradict_MRR':round((contradict_MRR_c+contradict_MRR_inc)/contradict_total, 4),\n",
    "        'contradict_correct':contradict_correct,\n",
    "        'contradict_correct_mean_len':round(contradict_correct_len/contradict_correct, 1),\n",
    "        'contradict_MRR_c':round(contradict_MRR_c/contradict_correct, 4),\n",
    "        'contradict_incorrect':contradict_total-contradict_correct,\n",
    "        'contradict_incorrect_mean_len':round((contradict_total_len-contradict_correct_len)/(contradict_total-contradict_correct), 2),\n",
    "        'contradict_MRR_inc':round(contradict_MRR_inc/(contradict_total-contradict_correct), 4),\n",
    "    }\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2a9a998efd492cad28996eb7792bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenyutsai/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 45min 58s, sys: 32.1 s, total: 46min 30s\n",
      "Wall time: 25min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.1842,\n",
       " 'total_acc': 0.56,\n",
       " 'total_mean_len': 15.0,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.62,\n",
       " 'entail_mean_len': 15.5,\n",
       " 'entail_MRR': 0.2048,\n",
       " 'entail_correct': 185,\n",
       " 'entail_correct_mean_len': 14.9,\n",
       " 'entail_MRR_c': 0.2122,\n",
       " 'entail_incorrect': 115,\n",
       " 'entail_incorrect_mean_len': 16.65,\n",
       " 'entail_MRR_inc': 0.1928,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.62,\n",
       " 'neutral_mean_len': 13.7,\n",
       " 'neutral_MRR': 0.1621,\n",
       " 'neutral_correct': 130,\n",
       " 'neutral_correct_mean_len': 13.7,\n",
       " 'neutral_MRR_c': 0.1619,\n",
       " 'neutral_incorrect': 80,\n",
       " 'neutral_incorrect_mean_len': 13.62,\n",
       " 'neutral_MRR_inc': 0.1624,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.21,\n",
       " 'contradict_mean_len': 16.4,\n",
       " 'contradict_MRR': 0.1671,\n",
       " 'contradict_correct': 19,\n",
       " 'contradict_correct_mean_len': 13.7,\n",
       " 'contradict_MRR_c': 0.1834,\n",
       " 'contradict_incorrect': 71,\n",
       " 'contradict_incorrect_mean_len': 17.13,\n",
       " 'contradict_MRR_inc': 0.1627}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = torch.load('contra_63_24.pkl', map_location=torch.device('cpu'))\n",
    "model_multi_result = calculate(model, testloader, tokenizer, unique=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5dd16fb5f3a4ff597eb4e31272b413a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 47min 13s, sys: 34.1 s, total: 47min 47s\n",
      "Wall time: 27min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.4666,\n",
       " 'total_acc': 0.56,\n",
       " 'total_mean_len': 15.0,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.62,\n",
       " 'entail_mean_len': 15.5,\n",
       " 'entail_MRR': 0.5621,\n",
       " 'entail_correct': 185,\n",
       " 'entail_correct_mean_len': 14.9,\n",
       " 'entail_MRR_c': 0.5755,\n",
       " 'entail_incorrect': 115,\n",
       " 'entail_incorrect_mean_len': 16.65,\n",
       " 'entail_MRR_inc': 0.5405,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.62,\n",
       " 'neutral_mean_len': 13.7,\n",
       " 'neutral_MRR': 0.3305,\n",
       " 'neutral_correct': 130,\n",
       " 'neutral_correct_mean_len': 13.7,\n",
       " 'neutral_MRR_c': 0.3187,\n",
       " 'neutral_incorrect': 80,\n",
       " 'neutral_incorrect_mean_len': 13.62,\n",
       " 'neutral_MRR_inc': 0.3497,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.21,\n",
       " 'contradict_mean_len': 16.4,\n",
       " 'contradict_MRR': 0.4655,\n",
       " 'contradict_correct': 19,\n",
       " 'contradict_correct_mean_len': 13.7,\n",
       " 'contradict_MRR_c': 0.4719,\n",
       " 'contradict_incorrect': 71,\n",
       " 'contradict_incorrect_mean_len': 17.13,\n",
       " 'contradict_MRR_inc': 0.4638}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = torch.load('contra_63_24.pkl', map_location=torch.device('cpu'))\n",
    "model_multi_result_in_un = calculate(model, testloader, tokenizer, unique=True, in_un=True)\n",
    "model_multi_result_in_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d956aa1c3574cb1b4539cca4c6b3be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.0248,\n",
       " 'total_acc': 0.56,\n",
       " 'total_mean_len': 245.8,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.62,\n",
       " 'entail_mean_len': 262.5,\n",
       " 'entail_MRR': 0.0282,\n",
       " 'entail_correct': 185,\n",
       " 'entail_correct_mean_len': 253.2,\n",
       " 'entail_MRR_c': 0.0302,\n",
       " 'entail_incorrect': 115,\n",
       " 'entail_incorrect_mean_len': 277.53,\n",
       " 'entail_MRR_inc': 0.0249,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.62,\n",
       " 'neutral_mean_len': 209.0,\n",
       " 'neutral_MRR': 0.0217,\n",
       " 'neutral_correct': 130,\n",
       " 'neutral_correct_mean_len': 211.1,\n",
       " 'neutral_MRR_c': 0.0213,\n",
       " 'neutral_incorrect': 80,\n",
       " 'neutral_incorrect_mean_len': 205.65,\n",
       " 'neutral_MRR_inc': 0.0223,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.21,\n",
       " 'contradict_mean_len': 275.6,\n",
       " 'contradict_MRR': 0.0213,\n",
       " 'contradict_correct': 19,\n",
       " 'contradict_correct_mean_len': 230.4,\n",
       " 'contradict_MRR_c': 0.0249,\n",
       " 'contradict_incorrect': 71,\n",
       " 'contradict_incorrect_mean_len': 287.69,\n",
       " 'contradict_MRR_inc': 0.0203}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_single = torch.load('single_056.pkl',map_location=torch.device('cpu'))\n",
    "model_single_result = calculate(model_single, testloader, tokenizer, unique=True)\n",
    "model_single_result\n",
    "\n",
    "model = torch.load('contra_63_24.pkl', map_location=torch.device('cpu'))\n",
    "model_multi_result_non_unique = calculate(model, testloader, tokenizer)\n",
    "model_multi_result_non_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f09332e99e54e56803cefb206351f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 46min 55s, sys: 33.4 s, total: 47min 28s\n",
      "Wall time: 26min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.4116,\n",
       " 'total_acc': 0.52,\n",
       " 'total_mean_len': 15.0,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.44,\n",
       " 'entail_mean_len': 15.5,\n",
       " 'entail_MRR': 0.4951,\n",
       " 'entail_correct': 133,\n",
       " 'entail_correct_mean_len': 13.9,\n",
       " 'entail_MRR_c': 0.5375,\n",
       " 'entail_incorrect': 167,\n",
       " 'entail_incorrect_mean_len': 16.86,\n",
       " 'entail_MRR_inc': 0.4613,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.73,\n",
       " 'neutral_mean_len': 13.7,\n",
       " 'neutral_MRR': 0.3011,\n",
       " 'neutral_correct': 154,\n",
       " 'neutral_correct_mean_len': 13.6,\n",
       " 'neutral_MRR_c': 0.297,\n",
       " 'neutral_incorrect': 56,\n",
       " 'neutral_incorrect_mean_len': 13.82,\n",
       " 'neutral_MRR_inc': 0.3125,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.29,\n",
       " 'contradict_mean_len': 16.4,\n",
       " 'contradict_MRR': 0.3909,\n",
       " 'contradict_correct': 26,\n",
       " 'contradict_correct_mean_len': 17.6,\n",
       " 'contradict_MRR_c': 0.423,\n",
       " 'contradict_incorrect': 64,\n",
       " 'contradict_incorrect_mean_len': 15.92,\n",
       " 'contradict_MRR_inc': 0.3779}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_single = torch.load('single_056.pkl',map_location=torch.device('cpu'))\n",
    "model_single_result_in_un = calculate(model_single, testloader, tokenizer, unique=True, in_un=True)\n",
    "model_single_result_in_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7200d36e4ee94c8c9647f48e96d27361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.0225,\n",
       " 'total_acc': 0.52,\n",
       " 'total_mean_len': 245.8,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.44,\n",
       " 'entail_mean_len': 262.5,\n",
       " 'entail_MRR': 0.0256,\n",
       " 'entail_correct': 133,\n",
       " 'entail_correct_mean_len': 229.1,\n",
       " 'entail_MRR_c': 0.0295,\n",
       " 'entail_incorrect': 167,\n",
       " 'entail_incorrect_mean_len': 289.12,\n",
       " 'entail_MRR_inc': 0.0224,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.73,\n",
       " 'neutral_mean_len': 209.0,\n",
       " 'neutral_MRR': 0.0198,\n",
       " 'neutral_correct': 154,\n",
       " 'neutral_correct_mean_len': 212.0,\n",
       " 'neutral_MRR_c': 0.0197,\n",
       " 'neutral_incorrect': 56,\n",
       " 'neutral_incorrect_mean_len': 200.98,\n",
       " 'neutral_MRR_inc': 0.0202,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.29,\n",
       " 'contradict_mean_len': 275.6,\n",
       " 'contradict_MRR': 0.0185,\n",
       " 'contradict_correct': 26,\n",
       " 'contradict_correct_mean_len': 311.7,\n",
       " 'contradict_MRR_c': 0.0194,\n",
       " 'contradict_incorrect': 64,\n",
       " 'contradict_incorrect_mean_len': 260.92,\n",
       " 'contradict_MRR_inc': 0.0181}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_single = torch.load('single_056.pkl',map_location=torch.device('cpu'))\n",
    "model_single_result_non_unique = calculate(model_single, testloader, tokenizer)\n",
    "model_single_result_non_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be844a6fb7a4427bbeac6d4636a596bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 46min 27s, sys: 32.4 s, total: 46min 59s\n",
      "Wall time: 26min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.1777,\n",
       " 'total_acc': 0.46,\n",
       " 'total_mean_len': 15.0,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.8,\n",
       " 'entail_mean_len': 15.5,\n",
       " 'entail_MRR': 0.1961,\n",
       " 'entail_correct': 240,\n",
       " 'entail_correct_mean_len': 15.6,\n",
       " 'entail_MRR_c': 0.1987,\n",
       " 'entail_incorrect': 60,\n",
       " 'entail_incorrect_mean_len': 15.53,\n",
       " 'entail_MRR_inc': 0.1857,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.15,\n",
       " 'neutral_mean_len': 13.7,\n",
       " 'neutral_MRR': 0.1584,\n",
       " 'neutral_correct': 31,\n",
       " 'neutral_correct_mean_len': 14.1,\n",
       " 'neutral_MRR_c': 0.1548,\n",
       " 'neutral_incorrect': 179,\n",
       " 'neutral_incorrect_mean_len': 13.59,\n",
       " 'neutral_MRR_inc': 0.159,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.07,\n",
       " 'contradict_mean_len': 16.4,\n",
       " 'contradict_MRR': 0.1613,\n",
       " 'contradict_correct': 6,\n",
       " 'contradict_correct_mean_len': 19.3,\n",
       " 'contradict_MRR_c': 0.1167,\n",
       " 'contradict_incorrect': 84,\n",
       " 'contradict_incorrect_mean_len': 16.19,\n",
       " 'contradict_MRR_inc': 0.1645}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_pretrained = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased',output_attentions=True,\n",
    "                                                                  num_labels=3)\n",
    "model_pretrained_result_unique = calculate(model_pretrained, testloader, tokenizer, unique=True)\n",
    "model_pretrained_result_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63694b1742c4698863c127d65a92200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.4017,\n",
       " 'total_acc': 0.46,\n",
       " 'total_mean_len': 15.0,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.8,\n",
       " 'entail_mean_len': 15.5,\n",
       " 'entail_MRR': 0.4776,\n",
       " 'entail_correct': 240,\n",
       " 'entail_correct_mean_len': 15.6,\n",
       " 'entail_MRR_c': 0.4874,\n",
       " 'entail_incorrect': 60,\n",
       " 'entail_incorrect_mean_len': 15.53,\n",
       " 'entail_MRR_inc': 0.4384,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.15,\n",
       " 'neutral_mean_len': 13.7,\n",
       " 'neutral_MRR': 0.3015,\n",
       " 'neutral_correct': 31,\n",
       " 'neutral_correct_mean_len': 14.1,\n",
       " 'neutral_MRR_c': 0.2993,\n",
       " 'neutral_incorrect': 179,\n",
       " 'neutral_incorrect_mean_len': 13.59,\n",
       " 'neutral_MRR_inc': 0.3019,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.07,\n",
       " 'contradict_mean_len': 16.4,\n",
       " 'contradict_MRR': 0.3822,\n",
       " 'contradict_correct': 6,\n",
       " 'contradict_correct_mean_len': 19.3,\n",
       " 'contradict_MRR_c': 0.3117,\n",
       " 'contradict_incorrect': 84,\n",
       " 'contradict_incorrect_mean_len': 16.19,\n",
       " 'contradict_MRR_inc': 0.3873}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pretrained_result_in_un = calculate(model_pretrained, testloader, tokenizer, unique=True, in_un=True)\n",
    "model_pretrained_result_in_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc75734562174cb3b37a23a9741510cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.0222,\n",
       " 'total_acc': 0.46,\n",
       " 'total_mean_len': 245.8,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.8,\n",
       " 'entail_mean_len': 262.5,\n",
       " 'entail_MRR': 0.0248,\n",
       " 'entail_correct': 240,\n",
       " 'entail_correct_mean_len': 269.4,\n",
       " 'entail_MRR_c': 0.0245,\n",
       " 'entail_incorrect': 60,\n",
       " 'entail_incorrect_mean_len': 235.18,\n",
       " 'entail_MRR_inc': 0.0259,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.15,\n",
       " 'neutral_mean_len': 209.0,\n",
       " 'neutral_MRR': 0.0201,\n",
       " 'neutral_correct': 31,\n",
       " 'neutral_correct_mean_len': 196.4,\n",
       " 'neutral_MRR_c': 0.0203,\n",
       " 'neutral_incorrect': 179,\n",
       " 'neutral_incorrect_mean_len': 211.22,\n",
       " 'neutral_MRR_inc': 0.02,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.07,\n",
       " 'contradict_mean_len': 275.6,\n",
       " 'contradict_MRR': 0.0189,\n",
       " 'contradict_correct': 6,\n",
       " 'contradict_correct_mean_len': 296.3,\n",
       " 'contradict_MRR_c': 0.017,\n",
       " 'contradict_incorrect': 84,\n",
       " 'contradict_incorrect_mean_len': 274.12,\n",
       " 'contradict_MRR_inc': 0.0191}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pretrained_result_non_unique = calculate(model_pretrained, testloader, tokenizer)\n",
    "model_pretrained_result_non_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "#with open('output.csv', 'w', newline='') as csvfile:\n",
    "\n",
    "with open('pretrained_non_unique.csv', 'w') as f:\n",
    "    w = csv.DictWriter(f, model_pretrained_result_non_unique.keys())\n",
    "    w.writeheader()\n",
    "    w.writerow(model_pretrained_result_non_unique)\n",
    "\n",
    "with open('pretrained_unique.csv', 'w') as f:\n",
    "    w = csv.DictWriter(f, model_pretrained_result.keys())\n",
    "    w.writeheader()\n",
    "    w.writerow(model_pretrained_result_unique)\n",
    "    \n",
    "with open('pretrained_in_un.csv', 'w') as f:\n",
    "    w = csv.DictWriter(f, model_pretrained_result_in_un.keys())\n",
    "    w.writeheader()\n",
    "    w.writerow(model_pretrained_result_in_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_a = \"\"\"losail qatar afp torrential rain caused the seasonopening qatar motogp to be cancelled on sunday leaving officials and teams in a frenzy before deciding to race on monday instead at this floodlit desert venue. monsoonlike conditions accompanied by swirling winds arrived just moments before australia's casey stoner on pole position was due to lead defending world champion valentino rossi and the other riders away on the warmup lap. it's just unlucky with the weather said australian ducati rider stoner the 2007 world champion who was bidding for a third successive win here.\"\"\"\n",
    "sentence_b = \"valentino rossi won the seasonopening qatar motogp.\"\n",
    "test_sentence_a = \"\"\"torrential rain caused the seasonopening qatar motogp to be cancelled\"\"\"\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True)\n",
    "input_ids = inputs['input_ids'].to(device)\n",
    "input_ids.squeeze()\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze().tolist())\n",
    "token_type_ids = inputs['token_type_ids'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0703, -0.0253, -0.0086]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    attention = model_pretrained(input_ids, token_type_ids=token_type_ids)[-1]\n",
    "    logits = model_pretrained(input_ids, token_type_ids=token_type_ids)[0]\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['season',\n",
       " 'p',\n",
       " 'moto',\n",
       " 'opening',\n",
       " 'qa',\n",
       " 'g',\n",
       " 'tar',\n",
       " 'ino',\n",
       " 'ossi',\n",
       " 'r',\n",
       " 'valent',\n",
       " 'win',\n",
       " 'for',\n",
       " 'defending',\n",
       " '.',\n",
       " 'a',\n",
       " 'the',\n",
       " 'bidding',\n",
       " 'world',\n",
       " 'champion',\n",
       " 'rider',\n",
       " 'race',\n",
       " 'pole',\n",
       " 'af',\n",
       " 'lead',\n",
       " 'was',\n",
       " 'riders',\n",
       " 'and',\n",
       " 'who',\n",
       " 'australia',\n",
       " 'up',\n",
       " 'lap',\n",
       " 'cancelled',\n",
       " 'successive',\n",
       " 'third',\n",
       " 'frenzy',\n",
       " 'warm',\n",
       " 'torrential',\n",
       " 'venue',\n",
       " 'deciding',\n",
       " 'ati',\n",
       " 'il',\n",
       " 'officials',\n",
       " 'monsoon',\n",
       " 'stone',\n",
       " '2007',\n",
       " 'case',\n",
       " \"'\",\n",
       " 'flood',\n",
       " 'position',\n",
       " 'desert',\n",
       " 'sun',\n",
       " 'teams',\n",
       " 'mon',\n",
       " 'before',\n",
       " 'lucky',\n",
       " 'instead',\n",
       " 'just',\n",
       " 'conditions',\n",
       " 'n',\n",
       " 'this',\n",
       " 'un',\n",
       " 'duc',\n",
       " 'winds',\n",
       " 'to',\n",
       " 'weather',\n",
       " 'on',\n",
       " 'here',\n",
       " 'it',\n",
       " 'said',\n",
       " 'at',\n",
       " 'los',\n",
       " 'day',\n",
       " 'due',\n",
       " 'rain',\n",
       " 'by',\n",
       " 'arrived',\n",
       " 'y',\n",
       " 'caused',\n",
       " 'other',\n",
       " 'be',\n",
       " 's',\n",
       " 'leaving',\n",
       " 'with',\n",
       " 'lit',\n",
       " 'swirling',\n",
       " 'away',\n",
       " 'moments',\n",
       " 'accompanied',\n",
       " 'like',\n",
       " 'in']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn = format_attention(attention, tokens)  \n",
    "tokens = format_special_chars(tokens)\n",
    "sentence_b_start = token_type_ids[0].tolist().index(1)\n",
    "slice_a = slice(0, sentence_b_start)\n",
    "slice_b = slice(sentence_b_start, len(tokens))\n",
    "attn_data = attn[:, :, slice_a, slice_b]\n",
    "sentence_a_tokens = tokens[slice_a]\n",
    "sentence_b_tokens = tokens[slice_b]\n",
    "pair = pair_match(sentence_a_tokens, sentence_b_tokens, attn_data=attn_data)\n",
    "pair = sorted(pair, key=lambda pair: pair[2], reverse=True)\n",
    "pair = unique_pair_without_score(pair)\n",
    "pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = tokenizer.encode_plus(test_sentence_a, sentence_b, return_tensors='pt', add_special_tokens=False)\n",
    "test_input_ids = test_inputs['input_ids']\n",
    "test_input_ids.squeeze()\n",
    "test_tokens = tokenizer.convert_ids_to_tokens(test_input_ids.squeeze().tolist())\n",
    "test_token_type_ids = test_inputs['token_type_ids']\n",
    "test_tokens = format_special_chars(test_tokens)\n",
    "test_sentence_b_start = test_token_type_ids[0].tolist().index(1)\n",
    "test_slice_a = slice(0, test_sentence_b_start)\n",
    "test_slice_b = slice(test_sentence_b_start, len(test_tokens))\n",
    "test_sentence_a_tokens = test_tokens[test_slice_a]\n",
    "test_sentence_b_tokens = test_tokens[test_slice_b]\n",
    "test_pair = pair_match(test_sentence_a_tokens, test_sentence_b_tokens, attn_data=None)\n",
    "test_pair = unique_pair_without_score(test_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['torrential',\n",
       " 'rain',\n",
       " 'caused',\n",
       " 'the',\n",
       " 'season',\n",
       " 'opening',\n",
       " 'qa',\n",
       " 'tar',\n",
       " 'moto',\n",
       " 'g',\n",
       " 'p',\n",
       " 'to',\n",
       " 'be',\n",
       " 'cancelled']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(pair) &  set(test_pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect_union(test_pair, pair, top_k: int = None):\n",
    "    if top_k == None:\n",
    "        pair = pair[:len(test_pair)]\n",
    "        intersection = len(set(pair) &  set(test_pair))\n",
    "        union = len(set(test_pair) | set(pair))\n",
    "        score = intersection / union\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['season', 'p', 'moto', 'opening', 'qa', 'g', 'tar', 'ino', 'ossi', 'r', 'valent', 'win', 'for', 'defending'] ['torrential', 'rain', 'caused', 'the', 'season', 'opening', 'qa', 'tar', 'moto', 'g', 'p', 'to', 'be', 'cancelled']\n",
      "7\n",
      "21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersect_union(test_pair, pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19728723911600124"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MRR_calculate(test_pair, pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_pair_without_score(pair):\n",
    "    pairs = []\n",
    "    for token_a, token_b, score in pair:\n",
    "        if token_a != '' and token_b != '' and token_a not in pairs:\n",
    "            pairs.append(token_a)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = torch.load('test.pkl',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_single = torch.load('acc_0.5_complete.pkl',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataset import ConcatDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def format_special_chars(tokens):\n",
    "    return [t.replace('Ġ', ' ').replace('▁', ' ').replace('</w>', '').replace(' ', '') for t in tokens]\n",
    "\n",
    "def format_attention(attention, tokens):\n",
    "    \"\"\" Set special token <sep>, <cls> attention to zero and format the attention \"\"\"\n",
    "    # set special token's attention to zero\n",
    "    for i, t in enumerate(tokens):\n",
    "        if t in (\"<sep>\", \"<cls>\"):\n",
    "            for layer_attn in attention:\n",
    "                layer_attn[0, :, i, :] = 0\n",
    "                layer_attn[0, :, :, i] = 0\n",
    "    squeezed = []\n",
    "    for layer_attention in attention:\n",
    "        # 1 x num_heads x seq_len x seq_len\n",
    "        if len(layer_attention.shape) != 4:\n",
    "            raise ValueError(\"Wrong attention length, attention length must be 4\")\n",
    "        squeezed.append(layer_attention.squeeze(0))\n",
    "    # num_layers x num_heads x seq_len x seq_len\n",
    "    return torch.stack(squeezed)\n",
    "\n",
    "def look_score(attn_data, index_a, index_b):\n",
    "    \"\"\" Look pair attention score in layers, head \"\"\"\n",
    "    score = 0.\n",
    "    for layer in attn_data:\n",
    "        for head in layer:\n",
    "            score_individual = head[index_a][index_b].tolist()\n",
    "            score += score_individual\n",
    "    return round(score, 3)\n",
    "\n",
    "def pair_match(sentence_a_tokens, sentence_b_tokens, attn_data=None):\n",
    "    \"\"\" Matching each token in sentence_a and sentence_b and making pairs \"\"\"\n",
    "    pairs = []\n",
    "    for index_a in range(len(sentence_a_tokens)):\n",
    "        for index_b in range(len(sentence_b_tokens)):\n",
    "            if attn_data is not None:\n",
    "                score = look_score(attn_data, index_a, index_b)\n",
    "                pair = (sentence_a_tokens[index_a], sentence_b_tokens[index_b], score)\n",
    "                # filter the special token\n",
    "                if score != 0:\n",
    "                    pairs.append(pair)\n",
    "            else:\n",
    "                # for evaluation pairs\n",
    "                pair = (sentence_a_tokens[index_a], sentence_b_tokens[index_b])\n",
    "                pairs.append(pair)\n",
    "    return pairs\n",
    "\n",
    "def pair_without_score(pair):\n",
    "    \"\"\" Return pairs without score \"\"\"\n",
    "    pairs = []\n",
    "    for token_a, token_b, score in pair:\n",
    "        if token_a != '' and token_b != '':\n",
    "            pair = (token_a, token_b)\n",
    "            pairs.append(pair)\n",
    "    return pairs\n",
    "\n",
    "def MRR_calculate(pair_truth, pair_all):\n",
    "    final_score = 0.\n",
    "    for query in pair_truth:\n",
    "        for response in range(len(pair_all)):\n",
    "            if pair_all[response] == query:\n",
    "                score = 1/(response+1)\n",
    "                final_score += score\n",
    "    final_score = final_score/len(pair_truth)\n",
    "    return final_score\n",
    "\n",
    "def MRR_mean(pair_truth, pair_all, top_k, times):\n",
    "    \"\"\" Choose k tokens from tokens list for calculating MRR\"\"\"\n",
    "    filtered = random.choices(pair_truth, k=top_k)\n",
    "    final = 0.\n",
    "    for i in range(times):\n",
    "        score = MRR_calculate(filtered, pair_all)\n",
    "        final += score\n",
    "    final = final/times\n",
    "    return final\n",
    "\n",
    "def explainability_compare(model, tokenizer, sentence_a, sentence_b, test_sentence_a):\n",
    "    \"\"\" Evaluating MRR between model and attention span\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True)\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    input_ids.squeeze()\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze().tolist())\n",
    "    token_type_ids = inputs['token_type_ids'].to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n",
    "    \n",
    "    attn = format_attention(attention, tokens)  \n",
    "    tokens = format_special_chars(tokens)\n",
    "    sentence_b_start = token_type_ids[0].tolist().index(1)\n",
    "    slice_a = slice(0, sentence_b_start)\n",
    "    slice_b = slice(sentence_b_start, len(tokens))\n",
    "    attn_data = attn[:, :, slice_a, slice_b]\n",
    "    sentence_a_tokens = tokens[slice_a]\n",
    "    sentence_b_tokens = tokens[slice_b]\n",
    "    pair = pair_match(sentence_a_tokens, sentence_b_tokens, attn_data=attn_data)\n",
    "    pair = sorted(pair, key=lambda pair: pair[2], reverse=True)\n",
    "    pair = pair_without_score(pair)\n",
    "    \n",
    "    test_inputs = tokenizer.encode_plus(test_sentence_a, sentence_b, return_tensors='pt', add_special_tokens=False)\n",
    "    test_input_ids = test_inputs['input_ids']\n",
    "    test_input_ids.squeeze()\n",
    "    test_tokens = tokenizer.convert_ids_to_tokens(test_input_ids.squeeze().tolist())\n",
    "    test_token_type_ids = test_inputs['token_type_ids']\n",
    "    test_tokens = format_special_chars(test_tokens)\n",
    "    test_sentence_b_start = test_token_type_ids[0].tolist().index(1)\n",
    "    test_slice_a = slice(0, test_sentence_b_start)\n",
    "    test_slice_b = slice(test_sentence_b_start, len(test_tokens))\n",
    "    test_sentence_a_tokens = test_tokens[test_slice_a]\n",
    "    test_sentence_b_tokens = test_tokens[test_slice_b]\n",
    "    test_pair = pair_match(test_sentence_a_tokens, test_sentence_b_tokens, attn_data=None)\n",
    "\n",
    "    return MRR_calculate(test_pair, pair), len(test_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explainability_compare(model, tokenizer, sentence_a, sentence_b, test_sentence_a, unique=False, in_un=False):\n",
    "    \"\"\" Evaluating MRR between model and attention span\"\"\"\n",
    "    inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True)\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    input_ids.squeeze()\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze().tolist())\n",
    "    token_type_ids = inputs['token_type_ids'].to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n",
    "    \n",
    "    attn = format_attention(attention, tokens)  \n",
    "    tokens = format_special_chars(tokens)\n",
    "    sentence_b_start = token_type_ids[0].tolist().index(1)\n",
    "    slice_a = slice(0, sentence_b_start)\n",
    "    slice_b = slice(sentence_b_start, len(tokens))\n",
    "    attn_data = attn[:, :, slice_a, slice_b]\n",
    "    sentence_a_tokens = tokens[slice_a]\n",
    "    sentence_b_tokens = tokens[slice_b]\n",
    "    pair = pair_match(sentence_a_tokens, sentence_b_tokens, attn_data=attn_data)\n",
    "    pair = sorted(pair, key=lambda pair: pair[2], reverse=True)\n",
    "    if not unique:\n",
    "        pair = pair_without_score(pair)\n",
    "    else:\n",
    "        pair = unique_pair_without_score(pair)\n",
    "    \n",
    "    test_inputs = tokenizer.encode_plus(test_sentence_a, sentence_b, return_tensors='pt', add_special_tokens=False)\n",
    "    test_input_ids = test_inputs['input_ids']\n",
    "    test_input_ids.squeeze()\n",
    "    test_tokens = tokenizer.convert_ids_to_tokens(test_input_ids.squeeze().tolist())\n",
    "    test_token_type_ids = test_inputs['token_type_ids']\n",
    "    test_tokens = format_special_chars(test_tokens)\n",
    "    test_sentence_b_start = test_token_type_ids[0].tolist().index(1)\n",
    "    test_slice_a = slice(0, test_sentence_b_start)\n",
    "    test_slice_b = slice(test_sentence_b_start, len(test_tokens))\n",
    "    test_sentence_a_tokens = test_tokens[test_slice_a]\n",
    "    test_sentence_b_tokens = test_tokens[test_slice_b]\n",
    "    test_pair = pair_match(test_sentence_a_tokens, test_sentence_b_tokens, attn_data=None)\n",
    "    if unique or in_un:\n",
    "        test_pair = unique_pair_without_score(test_pair)\n",
    "    \n",
    "    if in_un:\n",
    "        score = intersect_union(test_pair, pair)\n",
    "    else:\n",
    "        score = MRR_calculate(test_pair, pair)\n",
    "\n",
    "    return score, len(test_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
