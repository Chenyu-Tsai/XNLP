{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers.modeling_utils import (WEIGHTS_NAME, PretrainedConfig, PreTrainedModel,\n",
    "                             SequenceSummary, PoolerAnswerClass, PoolerEndLogits, PoolerStartLogits)\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification, XLNetPreTrainedModel, XLNetModel\n",
    "from torch.nn import CrossEntropyLoss, BCEWithLogitsLoss\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from XLNet import XLNetForMultiSequenceClassification\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import re\n",
    "from utils import *\n",
    "from tqdm.notebook import tqdm\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_MRR(Dataset):\n",
    "    def __init__(self, mode, tokenizer):\n",
    "        assert mode in [\"data/RTE5_test\"]\n",
    "        self.mode = mode\n",
    "        self.df = pd.read_csv(mode + \".tsv\", sep=\"\\t\").fillna(\"\")\n",
    "        self.len = len(self.df)\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        text_a, text_b, text_eval, label, t3, t5, t7 = self.df.iloc[idx, :].values\n",
    "        label_tensor = torch.tensor(label)\n",
    "            \n",
    "        inputs = tokenizer.encode_plus(text_a, text_b, return_tensors='pt', add_special_tokens=True)\n",
    "        tokens_tensor = inputs['input_ids']\n",
    "        segments_tensor = inputs['token_type_ids']\n",
    "        masks_tensor = inputs['attention_mask']\n",
    "        \n",
    "        return (tokens_tensor, segments_tensor, masks_tensor, label_tensor, text_a, text_b, text_eval)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset_MRR(\"data/RTE5_test\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def create_mini_batch(samples):\n",
    "    tokens_tensors = [s[0] for s in samples]\n",
    "    segments_tensors = [s[1] for s in samples]\n",
    "    masks_tensors = [s[2] for s in samples]\n",
    "    text_a = [s[4] for s in samples]\n",
    "    text_b = [s[5] for s in samples]\n",
    "    text_eval = [s[6] for s in samples]\n",
    "    t3 = [s[7] for s in samples]\n",
    "    t5 = [s[8] for s in samples]\n",
    "    t7 = [s[9] for s in samples]\n",
    "    \n",
    "    \n",
    "    if samples[0][3] is not None:\n",
    "        label_ids = torch.stack([s[3] for s in samples])\n",
    "    else:\n",
    "        label_ids = None\n",
    "    \n",
    "    tokens_tensors = pad_sequence(tokens_tensors, \n",
    "                                  batch_first=True)\n",
    "    segments_tensors = pad_sequence(segments_tensors, \n",
    "                                    batch_first=True)\n",
    "    masks_tensors = pad_sequence(masks_tensors, \n",
    "                                    batch_first=True)\n",
    "    \n",
    "    \n",
    "    return tokens_tensors.squeeze(1), segments_tensors.squeeze(1), masks_tensors.squeeze(1), label_ids, text_a, text_b, text_eval, t3, t5, t7\n",
    "\n",
    "\n",
    "# 初始化回傳訓練樣本的 DataLoader\n",
    "# 利用 `collate_fn` 將 list of samples 合併成一個 mini-batch \n",
    "BATCH_SIZE = 1\n",
    "testloader = DataLoader(dataset, batch_size=1, collate_fn=create_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(model, dataloader, tokenizer, unique=False, in_un=False, top_k=None):\n",
    "    total = len(dataloader)\n",
    "    entail_total = 0\n",
    "    entail_total_len = 0\n",
    "    neutral_total = 0\n",
    "    neutral_total_len = 0\n",
    "    contradict_total = 0\n",
    "    contradict_total_len = 0\n",
    "    \n",
    "    entail_correct = 0\n",
    "    entail_correct_len = 0\n",
    "    neutral_correct = 0\n",
    "    neutral_correct_len = 0\n",
    "    contradict_correct = 0\n",
    "    contradict_correct_len = 0\n",
    "    \n",
    "    entail_MRR_c = 0.\n",
    "    neutral_MRR_c = 0.\n",
    "    contradict_MRR_c = 0.\n",
    "    \n",
    "    entail_MRR_inc = 0.\n",
    "    neutral_MRR_inc = 0.\n",
    "    contradict_MRR_inc = 0.\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data_iterator = tqdm(dataloader, desc='Iteration')\n",
    "        for data in data_iterator:\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "            # predict\n",
    "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            sentence_a = data[4][0]\n",
    "            sentence_b = data[5][0]\n",
    "            if top_k = 3:\n",
    "                eval_sentence = data[7][0]\n",
    "            elif top_k = 5:\n",
    "                eval_sentence = data[8][0]\n",
    "            elif top_k = 7:\n",
    "                eval_sentence = data[9][0]\n",
    "            else:\n",
    "                eval_sentence = data[5][0]\n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors)\n",
    "            logits = outputs[0]\n",
    "            _, pred = torch.max(logits.data, 1)\n",
    "            \n",
    "            # divide 3 class\n",
    "            label = data[3]\n",
    "            MRR, length = explainability_compare(model,\n",
    "                                                 tokenizer,\n",
    "                                                 sentence_a,\n",
    "                                                 sentence_b,\n",
    "                                                 eval_sentence,\n",
    "                                                 unique=unique,\n",
    "                                                 in_un=in_un,\n",
    "                                                 top_k=top_k,\n",
    "                                                )\n",
    "\n",
    "            if label == torch.tensor([0]):\n",
    "                entail_total += 1\n",
    "                entail_total_len += length\n",
    "                if pred == label:\n",
    "                    entail_correct += 1\n",
    "                    entail_correct_len += length\n",
    "                    entail_MRR_c += MRR\n",
    "                else:\n",
    "                    entail_MRR_inc += MRR\n",
    "            elif label == torch.tensor([1]):\n",
    "                neutral_total += 1\n",
    "                neutral_total_len += length\n",
    "                if pred == label:\n",
    "                    neutral_correct += 1\n",
    "                    neutral_correct_len += length\n",
    "                    neutral_MRR_c += MRR\n",
    "                else:\n",
    "                    neutral_MRR_inc += MRR\n",
    "            else:\n",
    "                contradict_total += 1\n",
    "                contradict_total_len += length\n",
    "                if pred == label:\n",
    "                    contradict_correct += 1\n",
    "                    contradict_correct_len += length\n",
    "                    contradict_MRR_c += MRR\n",
    "                else:\n",
    "                    contradict_MRR_inc += MRR\n",
    "    if contradict_correct_len == 0:\n",
    "        contradict_correct += 1\n",
    "        \n",
    "                    \n",
    "    \n",
    "    return {\n",
    "        'total':total,\n",
    "        'total_MRR':round((entail_MRR_c+entail_MRR_inc+\n",
    "                           neutral_MRR_c+neutral_MRR_inc+\n",
    "                           contradict_MRR_c+contradict_MRR_inc)/total, 4),\n",
    "        'total_acc':round((entail_correct+neutral_correct+contradict_correct)/total, 2),\n",
    "        'total_mean_len':round((entail_total_len+neutral_total_len+contradict_total_len)/total, 1),\n",
    "        'entail_total':entail_total,\n",
    "        'entail_acc':round(entail_correct/entail_total, 2),\n",
    "        'entail_mean_len':round(entail_total_len/entail_total, 1),\n",
    "        'entail_MRR':round((entail_MRR_c+entail_MRR_inc)/entail_total, 4),\n",
    "        'entail_correct':entail_correct,\n",
    "        'entail_correct_mean_len':round(entail_correct_len/entail_correct, 1),\n",
    "        'entail_MRR_c':round(entail_MRR_c/entail_correct, 4),\n",
    "        'entail_incorrect':entail_total-entail_correct,\n",
    "        'entail_incorrect_mean_len':round((entail_total_len-entail_correct_len)/(entail_total-entail_correct), 2),\n",
    "        'entail_MRR_inc':round(entail_MRR_inc/(entail_total-entail_correct), 4),\n",
    "        'neutral_total':neutral_total,\n",
    "        'neutral_acc':round(neutral_correct/neutral_total, 2),\n",
    "        'neutral_mean_len':round(neutral_total_len/neutral_total, 1),\n",
    "        'neutral_MRR':round((neutral_MRR_c+neutral_MRR_inc)/neutral_total, 4),\n",
    "        'neutral_correct':neutral_correct,\n",
    "        'neutral_correct_mean_len':round(neutral_correct_len/neutral_correct, 1),\n",
    "        'neutral_MRR_c':round(neutral_MRR_c/neutral_correct, 4),\n",
    "        'neutral_incorrect':neutral_total-neutral_correct,\n",
    "        'neutral_incorrect_mean_len':round((neutral_total_len-neutral_correct_len)/(neutral_total-neutral_correct), 2),\n",
    "        'neutral_MRR_inc':round(neutral_MRR_inc/(neutral_total-neutral_correct), 4),\n",
    "        'contradict_total':contradict_total,\n",
    "        'contradict_acc':round(contradict_correct/contradict_total, 2),\n",
    "        'contradict_mean_len':round(contradict_total_len/contradict_total, 1),\n",
    "        'contradict_MRR':round((contradict_MRR_c+contradict_MRR_inc)/contradict_total, 4),\n",
    "        'contradict_correct':contradict_correct,\n",
    "        'contradict_correct_mean_len':round(contradict_correct_len/contradict_correct, 1),\n",
    "        'contradict_MRR_c':round(contradict_MRR_c/contradict_correct, 4),\n",
    "        'contradict_incorrect':contradict_total-contradict_correct,\n",
    "        'contradict_incorrect_mean_len':round((contradict_total_len-contradict_correct_len)/(contradict_total-contradict_correct), 2),\n",
    "        'contradict_MRR_inc':round(contradict_MRR_inc/(contradict_total-contradict_correct), 4),\n",
    "    }\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2a9a998efd492cad28996eb7792bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenyutsai/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 45min 58s, sys: 32.1 s, total: 46min 30s\n",
      "Wall time: 25min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.1842,\n",
       " 'total_acc': 0.56,\n",
       " 'total_mean_len': 15.0,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.62,\n",
       " 'entail_mean_len': 15.5,\n",
       " 'entail_MRR': 0.2048,\n",
       " 'entail_correct': 185,\n",
       " 'entail_correct_mean_len': 14.9,\n",
       " 'entail_MRR_c': 0.2122,\n",
       " 'entail_incorrect': 115,\n",
       " 'entail_incorrect_mean_len': 16.65,\n",
       " 'entail_MRR_inc': 0.1928,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.62,\n",
       " 'neutral_mean_len': 13.7,\n",
       " 'neutral_MRR': 0.1621,\n",
       " 'neutral_correct': 130,\n",
       " 'neutral_correct_mean_len': 13.7,\n",
       " 'neutral_MRR_c': 0.1619,\n",
       " 'neutral_incorrect': 80,\n",
       " 'neutral_incorrect_mean_len': 13.62,\n",
       " 'neutral_MRR_inc': 0.1624,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.21,\n",
       " 'contradict_mean_len': 16.4,\n",
       " 'contradict_MRR': 0.1671,\n",
       " 'contradict_correct': 19,\n",
       " 'contradict_correct_mean_len': 13.7,\n",
       " 'contradict_MRR_c': 0.1834,\n",
       " 'contradict_incorrect': 71,\n",
       " 'contradict_incorrect_mean_len': 17.13,\n",
       " 'contradict_MRR_inc': 0.1627}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = torch.load('contra_63_24.pkl', map_location=torch.device('cpu'))\n",
    "model_multi_result = calculate(model, testloader, tokenizer, unique=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5dd16fb5f3a4ff597eb4e31272b413a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 47min 13s, sys: 34.1 s, total: 47min 47s\n",
      "Wall time: 27min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.4666,\n",
       " 'total_acc': 0.56,\n",
       " 'total_mean_len': 15.0,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.62,\n",
       " 'entail_mean_len': 15.5,\n",
       " 'entail_MRR': 0.5621,\n",
       " 'entail_correct': 185,\n",
       " 'entail_correct_mean_len': 14.9,\n",
       " 'entail_MRR_c': 0.5755,\n",
       " 'entail_incorrect': 115,\n",
       " 'entail_incorrect_mean_len': 16.65,\n",
       " 'entail_MRR_inc': 0.5405,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.62,\n",
       " 'neutral_mean_len': 13.7,\n",
       " 'neutral_MRR': 0.3305,\n",
       " 'neutral_correct': 130,\n",
       " 'neutral_correct_mean_len': 13.7,\n",
       " 'neutral_MRR_c': 0.3187,\n",
       " 'neutral_incorrect': 80,\n",
       " 'neutral_incorrect_mean_len': 13.62,\n",
       " 'neutral_MRR_inc': 0.3497,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.21,\n",
       " 'contradict_mean_len': 16.4,\n",
       " 'contradict_MRR': 0.4655,\n",
       " 'contradict_correct': 19,\n",
       " 'contradict_correct_mean_len': 13.7,\n",
       " 'contradict_MRR_c': 0.4719,\n",
       " 'contradict_incorrect': 71,\n",
       " 'contradict_incorrect_mean_len': 17.13,\n",
       " 'contradict_MRR_inc': 0.4638}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = torch.load('contra_63_24.pkl', map_location=torch.device('cpu'))\n",
    "model_multi_result_in_un = calculate(model, testloader, tokenizer, unique=True, in_un=True)\n",
    "model_multi_result_in_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d956aa1c3574cb1b4539cca4c6b3be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.0248,\n",
       " 'total_acc': 0.56,\n",
       " 'total_mean_len': 245.8,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.62,\n",
       " 'entail_mean_len': 262.5,\n",
       " 'entail_MRR': 0.0282,\n",
       " 'entail_correct': 185,\n",
       " 'entail_correct_mean_len': 253.2,\n",
       " 'entail_MRR_c': 0.0302,\n",
       " 'entail_incorrect': 115,\n",
       " 'entail_incorrect_mean_len': 277.53,\n",
       " 'entail_MRR_inc': 0.0249,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.62,\n",
       " 'neutral_mean_len': 209.0,\n",
       " 'neutral_MRR': 0.0217,\n",
       " 'neutral_correct': 130,\n",
       " 'neutral_correct_mean_len': 211.1,\n",
       " 'neutral_MRR_c': 0.0213,\n",
       " 'neutral_incorrect': 80,\n",
       " 'neutral_incorrect_mean_len': 205.65,\n",
       " 'neutral_MRR_inc': 0.0223,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.21,\n",
       " 'contradict_mean_len': 275.6,\n",
       " 'contradict_MRR': 0.0213,\n",
       " 'contradict_correct': 19,\n",
       " 'contradict_correct_mean_len': 230.4,\n",
       " 'contradict_MRR_c': 0.0249,\n",
       " 'contradict_incorrect': 71,\n",
       " 'contradict_incorrect_mean_len': 287.69,\n",
       " 'contradict_MRR_inc': 0.0203}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_single = torch.load('single_056.pkl',map_location=torch.device('cpu'))\n",
    "model_single_result = calculate(model_single, testloader, tokenizer, unique=True)\n",
    "model_single_result\n",
    "\n",
    "model = torch.load('contra_63_24.pkl', map_location=torch.device('cpu'))\n",
    "model_multi_result_non_unique = calculate(model, testloader, tokenizer)\n",
    "model_multi_result_non_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a5d33cbf224f7ab362777ce45722b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.0286,\n",
       " 'total_acc': 0.58,\n",
       " 'total_mean_len': 158.8,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.78,\n",
       " 'entail_mean_len': 171.2,\n",
       " 'entail_MRR': 0.0322,\n",
       " 'entail_correct': 233,\n",
       " 'entail_correct_mean_len': 168.4,\n",
       " 'entail_MRR_c': 0.0339,\n",
       " 'entail_incorrect': 67,\n",
       " 'entail_incorrect_mean_len': 181.19,\n",
       " 'entail_MRR_inc': 0.0262,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.44,\n",
       " 'neutral_mean_len': 134.8,\n",
       " 'neutral_MRR': 0.0247,\n",
       " 'neutral_correct': 93,\n",
       " 'neutral_correct_mean_len': 132.2,\n",
       " 'neutral_MRR_c': 0.0243,\n",
       " 'neutral_incorrect': 117,\n",
       " 'neutral_incorrect_mean_len': 136.88,\n",
       " 'neutral_MRR_inc': 0.0249,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.27,\n",
       " 'contradict_mean_len': 173.7,\n",
       " 'contradict_MRR': 0.026,\n",
       " 'contradict_correct': 24,\n",
       " 'contradict_correct_mean_len': 157.3,\n",
       " 'contradict_MRR_c': 0.0248,\n",
       " 'contradict_incorrect': 66,\n",
       " 'contradict_incorrect_mean_len': 179.62,\n",
       " 'contradict_MRR_inc': 0.0264}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('multi_0.59, 31.pkl', map_location=torch.device('cpu'))\n",
    "model_multi_result_non_unique = calculate(model, testloader, tokenizer)\n",
    "model_multi_result_non_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf56a5375cbe49d79eedc6a96574f8bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.0292,\n",
       " 'total_acc': 0.61,\n",
       " 'total_mean_len': 158.8,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.85,\n",
       " 'entail_mean_len': 171.2,\n",
       " 'entail_MRR': 0.0329,\n",
       " 'entail_correct': 255,\n",
       " 'entail_correct_mean_len': 170.3,\n",
       " 'entail_MRR_c': 0.0341,\n",
       " 'entail_incorrect': 45,\n",
       " 'entail_incorrect_mean_len': 176.42,\n",
       " 'entail_MRR_inc': 0.0258,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.45,\n",
       " 'neutral_mean_len': 134.8,\n",
       " 'neutral_MRR': 0.0251,\n",
       " 'neutral_correct': 94,\n",
       " 'neutral_correct_mean_len': 132.2,\n",
       " 'neutral_MRR_c': 0.0249,\n",
       " 'neutral_incorrect': 116,\n",
       " 'neutral_incorrect_mean_len': 136.93,\n",
       " 'neutral_MRR_inc': 0.0252,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.18,\n",
       " 'contradict_mean_len': 173.7,\n",
       " 'contradict_MRR': 0.0266,\n",
       " 'contradict_correct': 16,\n",
       " 'contradict_correct_mean_len': 148.9,\n",
       " 'contradict_MRR_c': 0.0261,\n",
       " 'contradict_incorrect': 74,\n",
       " 'contradict_incorrect_mean_len': 179.03,\n",
       " 'contradict_MRR_inc': 0.0267}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('multi_0.58, 21.pkl', map_location=torch.device('cpu'))\n",
    "model_multi_result_non_unique2 = calculate(model, testloader, tokenizer)\n",
    "model_multi_result_non_unique2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2f1da7bc3a458c8daf4bcee844ac0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.029,\n",
       " 'total_acc': 0.6,\n",
       " 'total_mean_len': 158.8,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.87,\n",
       " 'entail_mean_len': 171.2,\n",
       " 'entail_MRR': 0.0327,\n",
       " 'entail_correct': 260,\n",
       " 'entail_correct_mean_len': 169.4,\n",
       " 'entail_MRR_c': 0.0342,\n",
       " 'entail_incorrect': 40,\n",
       " 'entail_incorrect_mean_len': 183.25,\n",
       " 'entail_MRR_inc': 0.023,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.4,\n",
       " 'neutral_mean_len': 134.8,\n",
       " 'neutral_MRR': 0.0248,\n",
       " 'neutral_correct': 83,\n",
       " 'neutral_correct_mean_len': 131.4,\n",
       " 'neutral_MRR_c': 0.0247,\n",
       " 'neutral_incorrect': 127,\n",
       " 'neutral_incorrect_mean_len': 137.06,\n",
       " 'neutral_MRR_inc': 0.0249,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.17,\n",
       " 'contradict_mean_len': 173.7,\n",
       " 'contradict_MRR': 0.0263,\n",
       " 'contradict_correct': 15,\n",
       " 'contradict_correct_mean_len': 132.8,\n",
       " 'contradict_MRR_c': 0.0267,\n",
       " 'contradict_incorrect': 75,\n",
       " 'contradict_incorrect_mean_len': 181.84,\n",
       " 'contradict_MRR_inc': 0.0263}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('multi_0.58, 26.pkl', map_location=torch.device('cpu'))\n",
    "model_multi_result_non_unique3 = calculate(model, testloader, tokenizer)\n",
    "model_multi_result_non_unique3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50413c6daade440d8861ed8c577482d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.0223,\n",
       " 'total_acc': 0.6,\n",
       " 'total_mean_len': 158.8,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.85,\n",
       " 'entail_mean_len': 171.2,\n",
       " 'entail_MRR': 0.0247,\n",
       " 'entail_correct': 254,\n",
       " 'entail_correct_mean_len': 169.3,\n",
       " 'entail_MRR_c': 0.0252,\n",
       " 'entail_incorrect': 46,\n",
       " 'entail_incorrect_mean_len': 181.85,\n",
       " 'entail_MRR_inc': 0.0223,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.42,\n",
       " 'neutral_mean_len': 134.8,\n",
       " 'neutral_MRR': 0.0196,\n",
       " 'neutral_correct': 88,\n",
       " 'neutral_correct_mean_len': 132.4,\n",
       " 'neutral_MRR_c': 0.0198,\n",
       " 'neutral_incorrect': 122,\n",
       " 'neutral_incorrect_mean_len': 136.59,\n",
       " 'neutral_MRR_inc': 0.0194,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.21,\n",
       " 'contradict_mean_len': 173.7,\n",
       " 'contradict_MRR': 0.0203,\n",
       " 'contradict_correct': 19,\n",
       " 'contradict_correct_mean_len': 106.8,\n",
       " 'contradict_MRR_c': 0.0226,\n",
       " 'contradict_incorrect': 71,\n",
       " 'contradict_incorrect_mean_len': 191.56,\n",
       " 'contradict_MRR_inc': 0.0197}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('multi_0.6, 22, 15.pkl', map_location=torch.device('cpu'))\n",
    "model_multi_result_non_unique4 = calculate(model, testloader, tokenizer)\n",
    "model_multi_result_non_unique4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9ee1c85b444c6eb3845cb28bca67cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.0236,\n",
       " 'total_acc': 0.6,\n",
       " 'total_mean_len': 158.8,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.85,\n",
       " 'entail_mean_len': 171.2,\n",
       " 'entail_MRR': 0.0262,\n",
       " 'entail_correct': 255,\n",
       " 'entail_correct_mean_len': 170.2,\n",
       " 'entail_MRR_c': 0.0271,\n",
       " 'entail_incorrect': 45,\n",
       " 'entail_incorrect_mean_len': 177.31,\n",
       " 'entail_MRR_inc': 0.0212,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.42,\n",
       " 'neutral_mean_len': 134.8,\n",
       " 'neutral_MRR': 0.0206,\n",
       " 'neutral_correct': 88,\n",
       " 'neutral_correct_mean_len': 135.6,\n",
       " 'neutral_MRR_c': 0.0207,\n",
       " 'neutral_incorrect': 122,\n",
       " 'neutral_incorrect_mean_len': 134.28,\n",
       " 'neutral_MRR_inc': 0.0205,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.21,\n",
       " 'contradict_mean_len': 173.7,\n",
       " 'contradict_MRR': 0.0217,\n",
       " 'contradict_correct': 19,\n",
       " 'contradict_correct_mean_len': 171.4,\n",
       " 'contradict_MRR_c': 0.0211,\n",
       " 'contradict_incorrect': 71,\n",
       " 'contradict_incorrect_mean_len': 174.27,\n",
       " 'contradict_MRR_inc': 0.0219}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('multi_0.6, 26, 13.pkl', map_location=torch.device('cpu'))\n",
    "model_multi_result_non_unique5 = calculate(model, testloader, tokenizer)\n",
    "model_multi_result_non_unique5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4489fad9ae8244359d870891b778d9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.0347,\n",
       " 'total_acc': 0.61,\n",
       " 'total_mean_len': 158.8,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.81,\n",
       " 'entail_mean_len': 171.2,\n",
       " 'entail_MRR': 0.0386,\n",
       " 'entail_correct': 242,\n",
       " 'entail_correct_mean_len': 170.5,\n",
       " 'entail_MRR_c': 0.0408,\n",
       " 'entail_incorrect': 58,\n",
       " 'entail_incorrect_mean_len': 174.21,\n",
       " 'entail_MRR_inc': 0.0294,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.43,\n",
       " 'neutral_mean_len': 134.8,\n",
       " 'neutral_MRR': 0.0305,\n",
       " 'neutral_correct': 90,\n",
       " 'neutral_correct_mean_len': 135.2,\n",
       " 'neutral_MRR_c': 0.03,\n",
       " 'neutral_incorrect': 120,\n",
       " 'neutral_incorrect_mean_len': 134.53,\n",
       " 'neutral_MRR_inc': 0.0308,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.36,\n",
       " 'contradict_mean_len': 173.7,\n",
       " 'contradict_MRR': 0.0313,\n",
       " 'contradict_correct': 32,\n",
       " 'contradict_correct_mean_len': 173.1,\n",
       " 'contradict_MRR_c': 0.0297,\n",
       " 'contradict_incorrect': 58,\n",
       " 'contradict_incorrect_mean_len': 173.97,\n",
       " 'contradict_MRR_inc': 0.0321}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('multi_0.59, 43, 18.pkl', map_location=torch.device('cpu'))\n",
    "model_multi_result_non_unique59_43 = calculate(model, testloader, tokenizer)\n",
    "model_multi_result_non_unique59_43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24c35a0d27b404da120973708c25756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.025,\n",
       " 'total_acc': 0.56,\n",
       " 'total_mean_len': 244.5,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.62,\n",
       " 'entail_mean_len': 261.6,\n",
       " 'entail_MRR': 0.0283,\n",
       " 'entail_correct': 186,\n",
       " 'entail_correct_mean_len': 252.7,\n",
       " 'entail_MRR_c': 0.0303,\n",
       " 'entail_incorrect': 114,\n",
       " 'entail_incorrect_mean_len': 275.93,\n",
       " 'entail_MRR_inc': 0.0251,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.62,\n",
       " 'neutral_mean_len': 208.1,\n",
       " 'neutral_MRR': 0.0217,\n",
       " 'neutral_correct': 131,\n",
       " 'neutral_correct_mean_len': 209.6,\n",
       " 'neutral_MRR_c': 0.0214,\n",
       " 'neutral_incorrect': 79,\n",
       " 'neutral_incorrect_mean_len': 205.58,\n",
       " 'neutral_MRR_inc': 0.0222,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.21,\n",
       " 'contradict_mean_len': 272.8,\n",
       " 'contradict_MRR': 0.0216,\n",
       " 'contradict_correct': 19,\n",
       " 'contradict_correct_mean_len': 230.4,\n",
       " 'contradict_MRR_c': 0.025,\n",
       " 'contradict_incorrect': 71,\n",
       " 'contradict_incorrect_mean_len': 284.1,\n",
       " 'contradict_MRR_inc': 0.0207}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('contra_63_24.pkl', map_location=torch.device('cpu'))\n",
    "model_2multi_result_non_unique = calculate(model, testloader, tokenizer)\n",
    "model_2multi_result_non_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2967e1ae7acc4be7bb551e35bff24137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenyutsai/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.0185,\n",
       " 'total_acc': 0.64,\n",
       " 'total_mean_len': 158.8,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.83,\n",
       " 'entail_mean_len': 171.2,\n",
       " 'entail_MRR': 0.0201,\n",
       " 'entail_correct': 250,\n",
       " 'entail_correct_mean_len': 172.3,\n",
       " 'entail_MRR_c': 0.0201,\n",
       " 'entail_incorrect': 50,\n",
       " 'entail_incorrect_mean_len': 165.64,\n",
       " 'entail_MRR_inc': 0.0201,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.56,\n",
       " 'neutral_mean_len': 134.8,\n",
       " 'neutral_MRR': 0.0167,\n",
       " 'neutral_correct': 118,\n",
       " 'neutral_correct_mean_len': 130.9,\n",
       " 'neutral_MRR_c': 0.0172,\n",
       " 'neutral_incorrect': 92,\n",
       " 'neutral_incorrect_mean_len': 139.85,\n",
       " 'neutral_MRR_inc': 0.0161,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.18,\n",
       " 'contradict_mean_len': 173.7,\n",
       " 'contradict_MRR': 0.0173,\n",
       " 'contradict_correct': 16,\n",
       " 'contradict_correct_mean_len': 137.4,\n",
       " 'contradict_MRR_c': 0.0176,\n",
       " 'contradict_incorrect': 74,\n",
       " 'contradict_incorrect_mean_len': 181.51,\n",
       " 'contradict_MRR_inc': 0.0172}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('2multi_0.628333, 25.pkl', map_location=torch.device('cpu'))\n",
    "model_2multi_result_non_unique1 = calculate(model, testloader, tokenizer)\n",
    "model_2multi_result_non_unique1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f09332e99e54e56803cefb206351f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 46min 55s, sys: 33.4 s, total: 47min 28s\n",
      "Wall time: 26min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.4116,\n",
       " 'total_acc': 0.52,\n",
       " 'total_mean_len': 15.0,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.44,\n",
       " 'entail_mean_len': 15.5,\n",
       " 'entail_MRR': 0.4951,\n",
       " 'entail_correct': 133,\n",
       " 'entail_correct_mean_len': 13.9,\n",
       " 'entail_MRR_c': 0.5375,\n",
       " 'entail_incorrect': 167,\n",
       " 'entail_incorrect_mean_len': 16.86,\n",
       " 'entail_MRR_inc': 0.4613,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.73,\n",
       " 'neutral_mean_len': 13.7,\n",
       " 'neutral_MRR': 0.3011,\n",
       " 'neutral_correct': 154,\n",
       " 'neutral_correct_mean_len': 13.6,\n",
       " 'neutral_MRR_c': 0.297,\n",
       " 'neutral_incorrect': 56,\n",
       " 'neutral_incorrect_mean_len': 13.82,\n",
       " 'neutral_MRR_inc': 0.3125,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.29,\n",
       " 'contradict_mean_len': 16.4,\n",
       " 'contradict_MRR': 0.3909,\n",
       " 'contradict_correct': 26,\n",
       " 'contradict_correct_mean_len': 17.6,\n",
       " 'contradict_MRR_c': 0.423,\n",
       " 'contradict_incorrect': 64,\n",
       " 'contradict_incorrect_mean_len': 15.92,\n",
       " 'contradict_MRR_inc': 0.3779}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_single = torch.load('single_056.pkl',map_location=torch.device('cpu'))\n",
    "model_single_result_in_un = calculate(model_single, testloader, tokenizer, unique=True, in_un=True)\n",
    "model_single_result_in_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7200d36e4ee94c8c9647f48e96d27361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.0225,\n",
       " 'total_acc': 0.52,\n",
       " 'total_mean_len': 245.8,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.44,\n",
       " 'entail_mean_len': 262.5,\n",
       " 'entail_MRR': 0.0256,\n",
       " 'entail_correct': 133,\n",
       " 'entail_correct_mean_len': 229.1,\n",
       " 'entail_MRR_c': 0.0295,\n",
       " 'entail_incorrect': 167,\n",
       " 'entail_incorrect_mean_len': 289.12,\n",
       " 'entail_MRR_inc': 0.0224,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.73,\n",
       " 'neutral_mean_len': 209.0,\n",
       " 'neutral_MRR': 0.0198,\n",
       " 'neutral_correct': 154,\n",
       " 'neutral_correct_mean_len': 212.0,\n",
       " 'neutral_MRR_c': 0.0197,\n",
       " 'neutral_incorrect': 56,\n",
       " 'neutral_incorrect_mean_len': 200.98,\n",
       " 'neutral_MRR_inc': 0.0202,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.29,\n",
       " 'contradict_mean_len': 275.6,\n",
       " 'contradict_MRR': 0.0185,\n",
       " 'contradict_correct': 26,\n",
       " 'contradict_correct_mean_len': 311.7,\n",
       " 'contradict_MRR_c': 0.0194,\n",
       " 'contradict_incorrect': 64,\n",
       " 'contradict_incorrect_mean_len': 260.92,\n",
       " 'contradict_MRR_inc': 0.0181}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_single = torch.load('single_056.pkl',map_location=torch.device('cpu'))\n",
    "model_single_result_non_unique = calculate(model_single, testloader, tokenizer)\n",
    "model_single_result_non_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be844a6fb7a4427bbeac6d4636a596bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 46min 27s, sys: 32.4 s, total: 46min 59s\n",
      "Wall time: 26min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.1777,\n",
       " 'total_acc': 0.46,\n",
       " 'total_mean_len': 15.0,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.8,\n",
       " 'entail_mean_len': 15.5,\n",
       " 'entail_MRR': 0.1961,\n",
       " 'entail_correct': 240,\n",
       " 'entail_correct_mean_len': 15.6,\n",
       " 'entail_MRR_c': 0.1987,\n",
       " 'entail_incorrect': 60,\n",
       " 'entail_incorrect_mean_len': 15.53,\n",
       " 'entail_MRR_inc': 0.1857,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.15,\n",
       " 'neutral_mean_len': 13.7,\n",
       " 'neutral_MRR': 0.1584,\n",
       " 'neutral_correct': 31,\n",
       " 'neutral_correct_mean_len': 14.1,\n",
       " 'neutral_MRR_c': 0.1548,\n",
       " 'neutral_incorrect': 179,\n",
       " 'neutral_incorrect_mean_len': 13.59,\n",
       " 'neutral_MRR_inc': 0.159,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.07,\n",
       " 'contradict_mean_len': 16.4,\n",
       " 'contradict_MRR': 0.1613,\n",
       " 'contradict_correct': 6,\n",
       " 'contradict_correct_mean_len': 19.3,\n",
       " 'contradict_MRR_c': 0.1167,\n",
       " 'contradict_incorrect': 84,\n",
       " 'contradict_incorrect_mean_len': 16.19,\n",
       " 'contradict_MRR_inc': 0.1645}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_pretrained = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased',output_attentions=True,\n",
    "                                                                  num_labels=3)\n",
    "model_pretrained_result_unique = calculate(model_pretrained, testloader, tokenizer, unique=True)\n",
    "model_pretrained_result_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63694b1742c4698863c127d65a92200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.4017,\n",
       " 'total_acc': 0.46,\n",
       " 'total_mean_len': 15.0,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.8,\n",
       " 'entail_mean_len': 15.5,\n",
       " 'entail_MRR': 0.4776,\n",
       " 'entail_correct': 240,\n",
       " 'entail_correct_mean_len': 15.6,\n",
       " 'entail_MRR_c': 0.4874,\n",
       " 'entail_incorrect': 60,\n",
       " 'entail_incorrect_mean_len': 15.53,\n",
       " 'entail_MRR_inc': 0.4384,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.15,\n",
       " 'neutral_mean_len': 13.7,\n",
       " 'neutral_MRR': 0.3015,\n",
       " 'neutral_correct': 31,\n",
       " 'neutral_correct_mean_len': 14.1,\n",
       " 'neutral_MRR_c': 0.2993,\n",
       " 'neutral_incorrect': 179,\n",
       " 'neutral_incorrect_mean_len': 13.59,\n",
       " 'neutral_MRR_inc': 0.3019,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.07,\n",
       " 'contradict_mean_len': 16.4,\n",
       " 'contradict_MRR': 0.3822,\n",
       " 'contradict_correct': 6,\n",
       " 'contradict_correct_mean_len': 19.3,\n",
       " 'contradict_MRR_c': 0.3117,\n",
       " 'contradict_incorrect': 84,\n",
       " 'contradict_incorrect_mean_len': 16.19,\n",
       " 'contradict_MRR_inc': 0.3873}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pretrained_result_in_un = calculate(model_pretrained, testloader, tokenizer, unique=True, in_un=True)\n",
    "model_pretrained_result_in_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc75734562174cb3b37a23a9741510cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=600, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 600,\n",
       " 'total_MRR': 0.0222,\n",
       " 'total_acc': 0.46,\n",
       " 'total_mean_len': 245.8,\n",
       " 'entail_total': 300,\n",
       " 'entail_acc': 0.8,\n",
       " 'entail_mean_len': 262.5,\n",
       " 'entail_MRR': 0.0248,\n",
       " 'entail_correct': 240,\n",
       " 'entail_correct_mean_len': 269.4,\n",
       " 'entail_MRR_c': 0.0245,\n",
       " 'entail_incorrect': 60,\n",
       " 'entail_incorrect_mean_len': 235.18,\n",
       " 'entail_MRR_inc': 0.0259,\n",
       " 'neutral_total': 210,\n",
       " 'neutral_acc': 0.15,\n",
       " 'neutral_mean_len': 209.0,\n",
       " 'neutral_MRR': 0.0201,\n",
       " 'neutral_correct': 31,\n",
       " 'neutral_correct_mean_len': 196.4,\n",
       " 'neutral_MRR_c': 0.0203,\n",
       " 'neutral_incorrect': 179,\n",
       " 'neutral_incorrect_mean_len': 211.22,\n",
       " 'neutral_MRR_inc': 0.02,\n",
       " 'contradict_total': 90,\n",
       " 'contradict_acc': 0.07,\n",
       " 'contradict_mean_len': 275.6,\n",
       " 'contradict_MRR': 0.0189,\n",
       " 'contradict_correct': 6,\n",
       " 'contradict_correct_mean_len': 296.3,\n",
       " 'contradict_MRR_c': 0.017,\n",
       " 'contradict_incorrect': 84,\n",
       " 'contradict_incorrect_mean_len': 274.12,\n",
       " 'contradict_MRR_inc': 0.0191}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pretrained_result_non_unique = calculate(model_pretrained, testloader, tokenizer)\n",
    "model_pretrained_result_non_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "#with open('output.csv', 'w', newline='') as csvfile:\n",
    "\n",
    "with open('pretrained_non_unique.csv', 'w') as f:\n",
    "    w = csv.DictWriter(f, model_pretrained_result_non_unique.keys())\n",
    "    w.writeheader()\n",
    "    w.writerow(model_pretrained_result_non_unique)\n",
    "\n",
    "with open('pretrained_unique.csv', 'w') as f:\n",
    "    w = csv.DictWriter(f, model_pretrained_result.keys())\n",
    "    w.writeheader()\n",
    "    w.writerow(model_pretrained_result_unique)\n",
    "    \n",
    "with open('pretrained_in_un.csv', 'w') as f:\n",
    "    w = csv.DictWriter(f, model_pretrained_result_in_un.keys())\n",
    "    w.writeheader()\n",
    "    w.writerow(model_pretrained_result_in_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_a = \"\"\"losail qatar afp torrential rain caused the seasonopening qatar motogp to be cancelled on sunday leaving officials and teams in a frenzy before deciding to race on monday instead at this floodlit desert venue. monsoonlike conditions accompanied by swirling winds arrived just moments before australia's casey stoner on pole position was due to lead defending world champion valentino rossi and the other riders away on the warmup lap. it's just unlucky with the weather said australian ducati rider stoner the 2007 world champion who was bidding for a third successive win here.\"\"\"\n",
    "sentence_b = \"valentino rossi won the seasonopening qatar motogp.\"\n",
    "test_sentence_a = \"\"\"torrential rain caused the seasonopening qatar motogp to be cancelled\"\"\"\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True)\n",
    "input_ids = inputs['input_ids'].to(device)\n",
    "input_ids.squeeze()\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze().tolist())\n",
    "token_type_ids = inputs['token_type_ids'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0703, -0.0253, -0.0086]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    attention = model_pretrained(input_ids, token_type_ids=token_type_ids)[-1]\n",
    "    logits = model_pretrained(input_ids, token_type_ids=token_type_ids)[0]\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['season',\n",
       " 'p',\n",
       " 'moto',\n",
       " 'opening',\n",
       " 'qa',\n",
       " 'g',\n",
       " 'tar',\n",
       " 'ino',\n",
       " 'ossi',\n",
       " 'r',\n",
       " 'valent',\n",
       " 'win',\n",
       " 'for',\n",
       " 'defending',\n",
       " '.',\n",
       " 'a',\n",
       " 'the',\n",
       " 'bidding',\n",
       " 'world',\n",
       " 'champion',\n",
       " 'rider',\n",
       " 'race',\n",
       " 'pole',\n",
       " 'af',\n",
       " 'lead',\n",
       " 'was',\n",
       " 'riders',\n",
       " 'and',\n",
       " 'who',\n",
       " 'australia',\n",
       " 'up',\n",
       " 'lap',\n",
       " 'cancelled',\n",
       " 'successive',\n",
       " 'third',\n",
       " 'frenzy',\n",
       " 'warm',\n",
       " 'torrential',\n",
       " 'venue',\n",
       " 'deciding',\n",
       " 'ati',\n",
       " 'il',\n",
       " 'officials',\n",
       " 'monsoon',\n",
       " 'stone',\n",
       " '2007',\n",
       " 'case',\n",
       " \"'\",\n",
       " 'flood',\n",
       " 'position',\n",
       " 'desert',\n",
       " 'sun',\n",
       " 'teams',\n",
       " 'mon',\n",
       " 'before',\n",
       " 'lucky',\n",
       " 'instead',\n",
       " 'just',\n",
       " 'conditions',\n",
       " 'n',\n",
       " 'this',\n",
       " 'un',\n",
       " 'duc',\n",
       " 'winds',\n",
       " 'to',\n",
       " 'weather',\n",
       " 'on',\n",
       " 'here',\n",
       " 'it',\n",
       " 'said',\n",
       " 'at',\n",
       " 'los',\n",
       " 'day',\n",
       " 'due',\n",
       " 'rain',\n",
       " 'by',\n",
       " 'arrived',\n",
       " 'y',\n",
       " 'caused',\n",
       " 'other',\n",
       " 'be',\n",
       " 's',\n",
       " 'leaving',\n",
       " 'with',\n",
       " 'lit',\n",
       " 'swirling',\n",
       " 'away',\n",
       " 'moments',\n",
       " 'accompanied',\n",
       " 'like',\n",
       " 'in']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn = format_attention(attention, tokens)  \n",
    "tokens = format_special_chars(tokens)\n",
    "sentence_b_start = token_type_ids[0].tolist().index(1)\n",
    "slice_a = slice(0, sentence_b_start)\n",
    "slice_b = slice(sentence_b_start, len(tokens))\n",
    "attn_data = attn[:, :, slice_a, slice_b]\n",
    "sentence_a_tokens = tokens[slice_a]\n",
    "sentence_b_tokens = tokens[slice_b]\n",
    "pair = pair_match(sentence_a_tokens, sentence_b_tokens, attn_data=attn_data)\n",
    "pair = sorted(pair, key=lambda pair: pair[2], reverse=True)\n",
    "pair = unique_pair_without_score(pair)\n",
    "pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = tokenizer.encode_plus(test_sentence_a, sentence_b, return_tensors='pt', add_special_tokens=False)\n",
    "test_input_ids = test_inputs['input_ids']\n",
    "test_input_ids.squeeze()\n",
    "test_tokens = tokenizer.convert_ids_to_tokens(test_input_ids.squeeze().tolist())\n",
    "test_token_type_ids = test_inputs['token_type_ids']\n",
    "test_tokens = format_special_chars(test_tokens)\n",
    "test_sentence_b_start = test_token_type_ids[0].tolist().index(1)\n",
    "test_slice_a = slice(0, test_sentence_b_start)\n",
    "test_slice_b = slice(test_sentence_b_start, len(test_tokens))\n",
    "test_sentence_a_tokens = test_tokens[test_slice_a]\n",
    "test_sentence_b_tokens = test_tokens[test_slice_b]\n",
    "test_pair = pair_match(test_sentence_a_tokens, test_sentence_b_tokens, attn_data=None)\n",
    "test_pair = unique_pair_without_score(test_pair)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
