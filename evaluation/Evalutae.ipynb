{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers.modeling_utils import (WEIGHTS_NAME, PretrainedConfig, PreTrainedModel,\n",
    "                             SequenceSummary, PoolerAnswerClass, PoolerEndLogits, PoolerStartLogits)\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification, XLNetPreTrainedModel, XLNetModel\n",
    "from torch.nn import CrossEntropyLoss, BCEWithLogitsLoss\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import re\n",
    "from utils import *\n",
    "from tqdm.notebook import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_MRR(Dataset):\n",
    "    def __init__(self, mode, tokenizer):\n",
    "        assert mode in [\"test_2\"]\n",
    "        self.mode = mode\n",
    "        self.df = pd.read_csv(mode + \".tsv\", sep=\"\\t\").fillna(\"\")\n",
    "        self.len = len(self.df)\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        text_a, text_b, text_eval, label = self.df.iloc[idx, :].values\n",
    "        label_tensor = torch.tensor(label)\n",
    "            \n",
    "        # sentence_a tokens\n",
    "        word_pieces = []\n",
    "        tokens_a = self.tokenizer.tokenize(text_a + '<SEP>')\n",
    "        word_pieces += tokens_a\n",
    "        len_a = len(tokens_a)\n",
    "        \n",
    "        # sentence_b tokens\n",
    "        tokens_b = self.tokenizer.tokenize(text_b + '<SEP><CLS>')\n",
    "        word_pieces += tokens_b\n",
    "        len_b = len(word_pieces) - len_a\n",
    "        \n",
    "        # 將 token 序列轉換成索引序列\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "        tokens_tensor = torch.tensor(ids)\n",
    "        \n",
    "        # 將第一句 token 位置設為 0，其他為 1 表示第二句\n",
    "        segments_tensor = torch.tensor([0] * len_a + [1] * (len_b-1) + [2], \n",
    "                                        dtype=torch.long)\n",
    "        \n",
    "        return (tokens_tensor, segments_tensor, label_tensor, text_a, text_b, text_eval)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset_MRR(\"test_2\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def create_mini_batch(samples):\n",
    "    tokens_tensors = [s[0] for s in samples]\n",
    "    segments_tensors = [s[1] for s in samples]\n",
    "    text_a = [s[3] for s in samples]\n",
    "    text_b = [s[4] for s in samples]\n",
    "    text_eval = [s[5] for s in samples]\n",
    "    \n",
    "    if samples[0][2] is not None:\n",
    "        label_ids = torch.stack([s[2] for s in samples])\n",
    "    else:\n",
    "        label_ids = None\n",
    "    \n",
    "    # zero pad 到同一序列長度\n",
    "    tokens_tensors = pad_sequence(tokens_tensors, \n",
    "                                  batch_first=True)\n",
    "    segments_tensors = pad_sequence(segments_tensors, \n",
    "                                    batch_first=True)\n",
    "    \n",
    "    # attention masks，將 tokens_tensors 裡頭不為 zero padding\n",
    "    # 的位置設為 1，讓 model 只關注這些位置的 tokens\n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape, \n",
    "                                dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(\n",
    "        tokens_tensors != 0, 1)\n",
    "    \n",
    "    return tokens_tensors, segments_tensors, masks_tensors, label_ids, text_a, text_b, text_eval\n",
    "\n",
    "\n",
    "# 初始化回傳訓練樣本的 DataLoader\n",
    "# 利用 `collate_fn` 將 list of samples 合併成一個 mini-batch \n",
    "BATCH_SIZE = 1\n",
    "testloader = DataLoader(dataset, batch_size=1, collate_fn=create_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(model, dataloader, tokenizer):\n",
    "    total = len(dataloader)\n",
    "    entail_total = 0\n",
    "    entail_total_len = 0\n",
    "    neutral_total = 0\n",
    "    neutral_total_len = 0\n",
    "    contradict_total = 0\n",
    "    contradict_total_len = 0\n",
    "    \n",
    "    entail_correct = 0\n",
    "    entail_correct_len = 0\n",
    "    neutral_correct = 0\n",
    "    neutral_correct_len = 0\n",
    "    contradict_correct = 0\n",
    "    contradict_correct_len = 0\n",
    "    \n",
    "    entail_MRR_c = 0.\n",
    "    neutral_MRR_c = 0.\n",
    "    contradict_MRR_c = 0.\n",
    "    \n",
    "    entail_MRR_inc = 0.\n",
    "    neutral_MRR_inc = 0.\n",
    "    contradict_MRR_inc = 0.\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data_iterator = tqdm(dataloader, desc='Iteration')\n",
    "        for data in data_iterator:\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "            # predict\n",
    "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            sentence_a = data[4][0]\n",
    "            sentence_b = data[5][0]\n",
    "            eval_sentence = data[6][0]\n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors)\n",
    "            logits = outputs[0]\n",
    "            _, pred = torch.max(logits.data, 1)\n",
    "            \n",
    "            # divide 3 class\n",
    "            label = data[3]\n",
    "            MRR, length = explainability_compare(model, tokenizer, sentence_a, sentence_b, eval_sentence)\n",
    "\n",
    "            if label == torch.tensor([0]):\n",
    "                entail_total += 1\n",
    "                entail_total_len += length\n",
    "                if pred == label:\n",
    "                    entail_correct += 1\n",
    "                    entail_correct_len += length\n",
    "                    entail_MRR_c += MRR\n",
    "                else:\n",
    "                    entail_MRR_inc += MRR\n",
    "            elif label == torch.tensor([1]):\n",
    "                neutral_total += 1\n",
    "                neutral_total_len += length\n",
    "                if pred == label:\n",
    "                    neutral_correct += 1\n",
    "                    neutral_correct_len += length\n",
    "                    neutral_MRR_c += MRR\n",
    "                else:\n",
    "                    neutral_MRR_inc += MRR\n",
    "            else:\n",
    "                contradict_total += 1\n",
    "                contradict_total_len += length\n",
    "                if pred == label:\n",
    "                    contradict_correct += 1\n",
    "                    contradict_correct_len += length\n",
    "                    contradict_MRR_c += MRR\n",
    "                else:\n",
    "                    contradict_MRR_inc += MRR\n",
    "    if contradict_correct_len == 0:\n",
    "        contradict_correct += 1\n",
    "        \n",
    "                    \n",
    "    \n",
    "    return {\n",
    "        'total':total,\n",
    "        'total_MRR':round((entail_MRR_c+entail_MRR_inc+\n",
    "                           neutral_MRR_c+neutral_MRR_inc+\n",
    "                           contradict_MRR_c+contradict_MRR_inc)/total, 4),\n",
    "        'total_acc':round((entail_correct+neutral_correct+contradict_correct)/total, 2),\n",
    "        'total_mean_len':round((entail_total_len+neutral_total_len+contradict_total_len)/total, 1),\n",
    "        'entail_total':entail_total,\n",
    "        'entail_acc':round(entail_correct/entail_total, 2),\n",
    "        'entail_mean_len':round(entail_total_len/entail_total, 1),\n",
    "        'entail_MRR':round((entail_MRR_c+entail_MRR_inc)/entail_total, 4),\n",
    "        'entail_correct':entail_correct,\n",
    "        'entail_correct_mean_len':round(entail_correct_len/entail_correct, 1),\n",
    "        'entail_MRR_c':round(entail_MRR_c/entail_correct, 4),\n",
    "        'entail_incorrect':entail_total-entail_correct,\n",
    "        'entail_incorrect_mean_len':round((entail_total_len-entail_correct_len)/(entail_total-entail_correct), 2),\n",
    "        'entail_MRR_inc':round(entail_MRR_inc/(entail_total-entail_correct), 4),\n",
    "        'neutral_total':neutral_total,\n",
    "        'neutral_acc':round(neutral_correct/neutral_total, 2),\n",
    "        'neutral_mean_len':round(neutral_total_len/neutral_total, 1),\n",
    "        'neutral_MRR':round((neutral_MRR_c+neutral_MRR_inc)/neutral_total, 4),\n",
    "        'neutral_correct':neutral_correct,\n",
    "        'neutral_correct_mean_len':round(neutral_correct_len/neutral_correct, 1),\n",
    "        'neutral_MRR_c':round(neutral_MRR_c/neutral_correct, 4),\n",
    "        'neutral_incorrect':neutral_total-neutral_correct,\n",
    "        'neutral_incorrect_mean_len':round((neutral_total_len-neutral_correct_len)/(neutral_total-neutral_correct), 2),\n",
    "        'neutral_MRR_inc':round(neutral_MRR_inc/(neutral_total-neutral_correct), 4),\n",
    "        'contradict_total':contradict_total,\n",
    "        'contradict_acc':round(contradict_correct/contradict_total, 2),\n",
    "        'contradict_mean_len':round(contradict_total_len/contradict_total, 1),\n",
    "        'contradict_MRR':round((contradict_MRR_c+contradict_MRR_inc)/contradict_total, 4),\n",
    "        'contradict_correct':contradict_correct,\n",
    "        'contradict_correct_mean_len':round(contradict_correct_len/contradict_correct, 1),\n",
    "        'contradict_MRR_c':round(contradict_MRR_c/contradict_correct, 4),\n",
    "        'contradict_incorrect':contradict_total-contradict_correct,\n",
    "        'contradict_incorrect_mean_len':round((contradict_total_len-contradict_correct_len)/(contradict_total-contradict_correct), 2),\n",
    "        'contradict_MRR_inc':round(contradict_MRR_inc/(contradict_total-contradict_correct), 4),\n",
    "    }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 540/540 [22:57<00:00,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40min 35s, sys: 27 s, total: 41min 2s\n",
      "Wall time: 22min 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 540,\n",
       " 'total_MRR': 0.0252,\n",
       " 'total_acc': 0.57,\n",
       " 'total_mean_len': 243.3,\n",
       " 'entail_total': 270,\n",
       " 'entail_acc': 0.69,\n",
       " 'entail_mean_len': 259.9,\n",
       " 'entail_MRR': 0.0286,\n",
       " 'entail_correct': 187,\n",
       " 'entail_correct_mean_len': 247.3,\n",
       " 'entail_MRR_c': 0.0302,\n",
       " 'entail_incorrect': 83,\n",
       " 'entail_incorrect_mean_len': 288.29,\n",
       " 'entail_MRR_inc': 0.0249,\n",
       " 'neutral_total': 191,\n",
       " 'neutral_acc': 0.57,\n",
       " 'neutral_mean_len': 205.9,\n",
       " 'neutral_MRR': 0.0221,\n",
       " 'neutral_correct': 108,\n",
       " 'neutral_correct_mean_len': 206.7,\n",
       " 'neutral_MRR_c': 0.0219,\n",
       " 'neutral_incorrect': 83,\n",
       " 'neutral_incorrect_mean_len': 204.88,\n",
       " 'neutral_MRR_inc': 0.0223,\n",
       " 'contradict_total': 79,\n",
       " 'contradict_acc': 0.19,\n",
       " 'contradict_mean_len': 277.0,\n",
       " 'contradict_MRR': 0.0216,\n",
       " 'contradict_correct': 15,\n",
       " 'contradict_correct_mean_len': 243.4,\n",
       " 'contradict_MRR_c': 0.0245,\n",
       " 'contradict_incorrect': 64,\n",
       " 'contradict_incorrect_mean_len': 284.83,\n",
       " 'contradict_MRR_inc': 0.0209}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = torch.load('contra_63_24.pkl', map_location=torch.device('cpu'))\n",
    "model_multi_result = calculate(model, testloader, tokenizer)\n",
    "model_multi_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 540/540 [22:37<00:00,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40min 6s, sys: 26.9 s, total: 40min 32s\n",
      "Wall time: 22min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 540,\n",
       " 'total_MRR': 0.0228,\n",
       " 'total_acc': 0.54,\n",
       " 'total_mean_len': 243.3,\n",
       " 'entail_total': 270,\n",
       " 'entail_acc': 0.49,\n",
       " 'entail_mean_len': 259.9,\n",
       " 'entail_MRR': 0.026,\n",
       " 'entail_correct': 133,\n",
       " 'entail_correct_mean_len': 232.5,\n",
       " 'entail_MRR_c': 0.0293,\n",
       " 'entail_incorrect': 137,\n",
       " 'entail_incorrect_mean_len': 286.46,\n",
       " 'entail_MRR_inc': 0.0228,\n",
       " 'neutral_total': 191,\n",
       " 'neutral_acc': 0.74,\n",
       " 'neutral_mean_len': 205.9,\n",
       " 'neutral_MRR': 0.02,\n",
       " 'neutral_correct': 142,\n",
       " 'neutral_correct_mean_len': 204.8,\n",
       " 'neutral_MRR_c': 0.02,\n",
       " 'neutral_incorrect': 49,\n",
       " 'neutral_incorrect_mean_len': 208.98,\n",
       " 'neutral_MRR_inc': 0.0198,\n",
       " 'contradict_total': 79,\n",
       " 'contradict_acc': 0.24,\n",
       " 'contradict_mean_len': 277.0,\n",
       " 'contradict_MRR': 0.0185,\n",
       " 'contradict_correct': 19,\n",
       " 'contradict_correct_mean_len': 353.6,\n",
       " 'contradict_MRR_c': 0.0168,\n",
       " 'contradict_incorrect': 60,\n",
       " 'contradict_incorrect_mean_len': 252.7,\n",
       " 'contradict_MRR_inc': 0.0191}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_single = torch.load('single_056.pkl',map_location=torch.device('cpu'))\n",
    "model_single_result = calculate(model_single, testloader, tokenizer)\n",
    "model_single_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb3fd1248d7435bb9a9a9b4a2bd893d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=540, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 40min 46s, sys: 26 s, total: 41min 12s\n",
      "Wall time: 23min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 540,\n",
       " 'total_MRR': 0.0224,\n",
       " 'total_acc': 0.37,\n",
       " 'total_mean_len': 243.3,\n",
       " 'entail_total': 270,\n",
       " 'entail_acc': 0.46,\n",
       " 'entail_mean_len': 259.9,\n",
       " 'entail_MRR': 0.0249,\n",
       " 'entail_correct': 124,\n",
       " 'entail_correct_mean_len': 280.4,\n",
       " 'entail_MRR_c': 0.0234,\n",
       " 'entail_incorrect': 146,\n",
       " 'entail_incorrect_mean_len': 242.44,\n",
       " 'entail_MRR_inc': 0.0262,\n",
       " 'neutral_total': 191,\n",
       " 'neutral_acc': 0.29,\n",
       " 'neutral_mean_len': 205.9,\n",
       " 'neutral_MRR': 0.0203,\n",
       " 'neutral_correct': 55,\n",
       " 'neutral_correct_mean_len': 204.3,\n",
       " 'neutral_MRR_c': 0.023,\n",
       " 'neutral_incorrect': 136,\n",
       " 'neutral_incorrect_mean_len': 206.56,\n",
       " 'neutral_MRR_inc': 0.0192,\n",
       " 'contradict_total': 79,\n",
       " 'contradict_acc': 0.29,\n",
       " 'contradict_mean_len': 277.0,\n",
       " 'contradict_MRR': 0.0191,\n",
       " 'contradict_correct': 23,\n",
       " 'contradict_correct_mean_len': 259.7,\n",
       " 'contradict_MRR_c': 0.02,\n",
       " 'contradict_incorrect': 56,\n",
       " 'contradict_incorrect_mean_len': 284.04,\n",
       " 'contradict_MRR_inc': 0.0187}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_pretrained = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased',output_attentions=True,\n",
    "                                                                  num_labels=3)\n",
    "model_pretrained_result = calculate(model_pretrained, testloader, tokenizer)\n",
    "model_pretrained_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "#with open('output.csv', 'w', newline='') as csvfile:\n",
    "\n",
    "with open('multi_252.csv', 'w') as f:\n",
    "    w = csv.DictWriter(f, model_multi_result.keys())\n",
    "    w.writeheader()\n",
    "    w.writerow(model_multi_result)\n",
    "\n",
    "# with open('single.csv', 'w') as f:\n",
    "#     w = csv.DictWriter(f, model_single_result.keys())\n",
    "#     w.writeheader()\n",
    "#     w.writerow(model_single_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_a = \"\"\"losail qatar afp torrential rain caused the seasonopening qatar motogp to be cancelled on sunday leaving officials and teams in a frenzy before deciding to race on monday instead at this floodlit desert venue. monsoonlike conditions accompanied by swirling winds arrived just moments before australia's casey stoner on pole position was due to lead defending world champion valentino rossi and the other riders away on the warmup lap. it's just unlucky with the weather said australian ducati rider stoner the 2007 world champion who was bidding for a third successive win here.\"\"\"\n",
    "sentence_b = \"valentino rossi won the seasonopening qatar motogp.\"\n",
    "test_sentence_a = \"\"\"torrential rain caused the seasonopening qatar motogp to be cancelled\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True)\n",
    "input_ids = inputs['input_ids'].to(device)\n",
    "input_ids.squeeze()\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze().tolist())\n",
    "token_type_ids = inputs['token_type_ids'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = model(input_ids, token_type_ids=token_type_ids)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    attention = model(input_ids, token_type_ids=token_type_ids)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('season', 'season'),\n",
       " ('opening', 'opening'),\n",
       " ('moto', 'moto'),\n",
       " ('p', 'p'),\n",
       " ('g', 'g'),\n",
       " ('ino', 'ino'),\n",
       " ('tar', 'tar'),\n",
       " ('ossi', 'ossi'),\n",
       " ('r', 'r'),\n",
       " ('qa', 'qa'),\n",
       " ('valent', 'valent'),\n",
       " ('tar', 'tar'),\n",
       " ('qa', 'qa'),\n",
       " ('season', 'opening'),\n",
       " ('win', 'won'),\n",
       " ('p', 'p'),\n",
       " ('the', 'the'),\n",
       " ('g', 'moto'),\n",
       " ('p', '.'),\n",
       " ('.', '.'),\n",
       " ('opening', 'season'),\n",
       " ('defending', 'won'),\n",
       " ('a', 'won'),\n",
       " ('for', 'won'),\n",
       " ('p', '.'),\n",
       " ('af', '.'),\n",
       " ('defending', 'the'),\n",
       " ('bidding', 'won'),\n",
       " ('g', 'p'),\n",
       " ('.', 'won'),\n",
       " ('p', 'moto'),\n",
       " ('tar', 'qa'),\n",
       " ('champion', 'won'),\n",
       " ('defending', '.'),\n",
       " ('qa', 'tar'),\n",
       " ('p', 'g'),\n",
       " ('qa', 'opening'),\n",
       " ('world', '.'),\n",
       " ('up', 'opening'),\n",
       " ('torrential', '.'),\n",
       " ('tar', 'moto'),\n",
       " (\"'\", '.'),\n",
       " ('season', 'the'),\n",
       " ('case', '.'),\n",
       " ('.', '.'),\n",
       " ('champion', 'won'),\n",
       " ('world', 'the'),\n",
       " ('position', '.'),\n",
       " ('sun', '.'),\n",
       " ('champion', '.'),\n",
       " ('the', 'won'),\n",
       " ('riders', '.'),\n",
       " ('the', '.'),\n",
       " ('opening', 'the'),\n",
       " ('and', 'ossi'),\n",
       " ('it', '.'),\n",
       " ('world', 'won'),\n",
       " ('just', '.'),\n",
       " ('successive', 'won'),\n",
       " ('bidding', 'the'),\n",
       " ('.', '.'),\n",
       " ('and', '.'),\n",
       " ('was', 'won'),\n",
       " ('the', '.'),\n",
       " ('r', 'won'),\n",
       " ('the', 'the'),\n",
       " ('ossi', '.'),\n",
       " ('the', 'season'),\n",
       " ('un', '.'),\n",
       " ('deciding', '.'),\n",
       " ('cancelled', '.'),\n",
       " ('.', 'valent'),\n",
       " ('champion', 'the'),\n",
       " ('said', '.'),\n",
       " ('to', '.'),\n",
       " ('who', 'won'),\n",
       " ('before', '.'),\n",
       " ('australia', '.'),\n",
       " ('venue', '.'),\n",
       " ('race', '.'),\n",
       " ('for', 'the'),\n",
       " ('pole', '.'),\n",
       " ('officials', '.'),\n",
       " ('this', '.'),\n",
       " ('opening', '.'),\n",
       " ('instead', '.'),\n",
       " ('weather', '.'),\n",
       " ('desert', '.'),\n",
       " ('other', '.'),\n",
       " ('just', '.'),\n",
       " ('the', '.'),\n",
       " ('leaving', '.'),\n",
       " ('a', '.'),\n",
       " ('s', '.'),\n",
       " ('season', '.'),\n",
       " ('pole', 'the'),\n",
       " ('a', '.'),\n",
       " ('day', '.'),\n",
       " ('rider', 'the'),\n",
       " ('.', 'the'),\n",
       " ('moto', 'g'),\n",
       " ('il', '.'),\n",
       " ('moto', 'tar'),\n",
       " ('ossi', 'won'),\n",
       " ('ino', '.'),\n",
       " ('bidding', '.'),\n",
       " ('successive', 'the'),\n",
       " ('the', 'opening'),\n",
       " ('day', '.'),\n",
       " ('caused', '.'),\n",
       " ('australia', '.'),\n",
       " ('with', '.'),\n",
       " ('the', '.'),\n",
       " ('at', '.'),\n",
       " ('teams', '.'),\n",
       " ('here', '.'),\n",
       " ('win', '.'),\n",
       " ('on', '.'),\n",
       " ('qa', '.'),\n",
       " ('los', '.'),\n",
       " ('third', 'won'),\n",
       " ('p', 'the'),\n",
       " ('tar', '.'),\n",
       " ('r', 'moto'),\n",
       " ('who', '.'),\n",
       " ('race', 'the'),\n",
       " ('mon', '.'),\n",
       " ('world', 'the'),\n",
       " ('be', '.'),\n",
       " ('lucky', '.'),\n",
       " ('stone', '.'),\n",
       " ('by', '.'),\n",
       " ('defending', 'opening'),\n",
       " ('rider', '.'),\n",
       " ('arrived', '.'),\n",
       " ('the', '.'),\n",
       " ('successive', '.'),\n",
       " ('on', '.'),\n",
       " ('moto', '.'),\n",
       " ('flood', '.'),\n",
       " ('2007', '.'),\n",
       " ('il', 'the'),\n",
       " ('ino', 'ossi'),\n",
       " ('defending', 'season'),\n",
       " ('to', 'won'),\n",
       " ('venue', 'the'),\n",
       " ('rain', '.'),\n",
       " ('was', '.'),\n",
       " ('lead', 'the'),\n",
       " ('r', 'ossi'),\n",
       " ('cancelled', 'the'),\n",
       " ('valent', '.'),\n",
       " ('r', 'ossi'),\n",
       " ('tar', 'opening'),\n",
       " ('lap', '.'),\n",
       " ('for', '.'),\n",
       " ('the', 'won'),\n",
       " ('moments', '.'),\n",
       " ('pole', 'won'),\n",
       " ('lap', 'the'),\n",
       " ('p', 'won'),\n",
       " ('to', '.'),\n",
       " ('a', 'the'),\n",
       " ('world', 'season'),\n",
       " ('r', 'r'),\n",
       " ('lead', 'won'),\n",
       " ('lead', '.'),\n",
       " ('r', '.'),\n",
       " ('successive', 'opening'),\n",
       " ('up', '.'),\n",
       " ('before', '.'),\n",
       " ('warm', '.'),\n",
       " ('win', 'the'),\n",
       " ('australia', 'the'),\n",
       " ('position', 'the'),\n",
       " ('riders', 'the'),\n",
       " ('here', 'the'),\n",
       " ('frenzy', '.'),\n",
       " ('the', 'the'),\n",
       " ('who', 'the'),\n",
       " ('conditions', '.'),\n",
       " ('2007', 'the'),\n",
       " ('position', 'won'),\n",
       " ('officials', 'the'),\n",
       " ('a', '.'),\n",
       " ('deciding', 'the'),\n",
       " ('lit', '.'),\n",
       " ('world', '.'),\n",
       " ('r', '.'),\n",
       " ('qa', 'moto'),\n",
       " ('warm', 'the'),\n",
       " ('.', 'ossi'),\n",
       " ('on', '.'),\n",
       " ('third', '.'),\n",
       " ('g', 'opening'),\n",
       " ('frenzy', 'the'),\n",
       " ('champion', '.'),\n",
       " ('g', 'tar'),\n",
       " ('valent', 'ino'),\n",
       " ('on', '.'),\n",
       " ('tar', 'the'),\n",
       " ('p', 'opening'),\n",
       " ('and', '.'),\n",
       " ('before', 'the'),\n",
       " ('swirling', '.'),\n",
       " ('stone', '.'),\n",
       " ('winds', '.'),\n",
       " ('was', '.'),\n",
       " ('tar', 'moto'),\n",
       " ('world', 'won'),\n",
       " ('due', '.'),\n",
       " ('instead', 'the'),\n",
       " ('ino', 'valent'),\n",
       " ('the', 'won'),\n",
       " (\"'\", 'the'),\n",
       " ('r', '.'),\n",
       " ('r', 'won'),\n",
       " ('.', 'ino'),\n",
       " ('y', '.'),\n",
       " ('monsoon', '.'),\n",
       " ('race', 'moto'),\n",
       " ('race', 'won'),\n",
       " ('australia', 'the'),\n",
       " (\"'\", '.'),\n",
       " ('opening', 'won'),\n",
       " ('ati', '.'),\n",
       " ('qa', 'opening'),\n",
       " ('los', 'the'),\n",
       " ('here', 'won'),\n",
       " ('conditions', 'the'),\n",
       " (\"'\", 'the'),\n",
       " ('g', '.'),\n",
       " ('like', '.'),\n",
       " ('tar', 'won'),\n",
       " ('champion', 'the'),\n",
       " ('g', 'the'),\n",
       " ('teams', 'the'),\n",
       " ('away', '.'),\n",
       " ('ossi', 'the'),\n",
       " ('tar', 'p'),\n",
       " ('accompanied', '.'),\n",
       " ('r', 'the'),\n",
       " ('af', 'won'),\n",
       " ('said', 'won'),\n",
       " ('2007', 'won'),\n",
       " ('this', 'the'),\n",
       " ('s', '.'),\n",
       " ('moto', 'the'),\n",
       " ('the', 'won'),\n",
       " ('p', 'the'),\n",
       " ('champion', 'moto'),\n",
       " ('n', '.'),\n",
       " ('qa', 'tar'),\n",
       " ('moto', 'p'),\n",
       " ('in', '.'),\n",
       " ('monsoon', 'the'),\n",
       " ('ino', 'the'),\n",
       " ('p', 'won'),\n",
       " ('duc', '.'),\n",
       " ('arrived', 'won'),\n",
       " ('to', '.'),\n",
       " ('cancelled', 'won'),\n",
       " ('ino', 'won'),\n",
       " ('.', 'r'),\n",
       " ('world', 'opening'),\n",
       " ('weather', 'the'),\n",
       " ('r', 'valent'),\n",
       " ('qa', 'the'),\n",
       " ('third', 'the'),\n",
       " ('qa', 'moto'),\n",
       " ('ati', 'the'),\n",
       " ('winds', 'the'),\n",
       " ('desert', 'the'),\n",
       " ('qa', '.'),\n",
       " ('lucky', 'won'),\n",
       " ('season', 'won'),\n",
       " ('ino', 'opening'),\n",
       " ('away', 'won'),\n",
       " ('weather', 'won'),\n",
       " ('.', 'the'),\n",
       " ('tar', 'the'),\n",
       " ('qa', 'season'),\n",
       " ('up', 'the'),\n",
       " ('los', 'won'),\n",
       " ('g', 'season'),\n",
       " ('was', 'the'),\n",
       " ('and', 'won'),\n",
       " ('af', 'the'),\n",
       " ('il', 'won'),\n",
       " ('venue', 'moto'),\n",
       " ('it', 'the'),\n",
       " ('successive', 'season'),\n",
       " ('qa', 'won'),\n",
       " ('riders', 'moto'),\n",
       " ('on', 'won'),\n",
       " ('moto', 'qa'),\n",
       " ('instead', 'won'),\n",
       " ('riders', 'won'),\n",
       " ('champion', 'valent'),\n",
       " ('day', 'the'),\n",
       " ('stone', 'valent'),\n",
       " ('ino', 'tar'),\n",
       " ('the', 'the'),\n",
       " ('ossi', 'p'),\n",
       " ('y', 'the'),\n",
       " ('lucky', 'the'),\n",
       " ('tar', '.'),\n",
       " ('torrential', 'the'),\n",
       " ('caused', 'the'),\n",
       " ('due', 'the'),\n",
       " ('tar', 'opening'),\n",
       " ('moto', 'season'),\n",
       " ('arrived', 'opening'),\n",
       " ('lap', 'won'),\n",
       " ('los', 'valent'),\n",
       " ('ino', 'r'),\n",
       " ('ino', 'moto'),\n",
       " ('here', 'opening'),\n",
       " ('valent', 'ossi'),\n",
       " ('venue', 'opening'),\n",
       " ('s', 'the'),\n",
       " ('up', 'won'),\n",
       " ('s', 'won'),\n",
       " ('was', 'won'),\n",
       " ('rain', 'the'),\n",
       " ('qa', 'season'),\n",
       " ('other', 'won'),\n",
       " ('s', 'the'),\n",
       " ('g', 'won'),\n",
       " ('flood', 'the'),\n",
       " ('r', 'ino'),\n",
       " ('.', 'season'),\n",
       " ('to', 'the'),\n",
       " ('ati', 'ino'),\n",
       " ('be', 'won'),\n",
       " ('rider', 'won'),\n",
       " ('los', 'ino'),\n",
       " ('ossi', 'ino'),\n",
       " ('the', 'won'),\n",
       " ('p', 'season'),\n",
       " ('away', 'the'),\n",
       " ('rider', 'moto'),\n",
       " ('a', 'the'),\n",
       " ('ossi', 'r'),\n",
       " ('warm', 'won'),\n",
       " (\"'\", 'won'),\n",
       " ('champion', 'ino'),\n",
       " ('a', 'valent'),\n",
       " ('r', 'valent'),\n",
       " ('arrived', 'the'),\n",
       " ('warm', 'season'),\n",
       " ('n', 'ino'),\n",
       " ('r', 'ino'),\n",
       " ('who', 'ino'),\n",
       " ('on', 'won'),\n",
       " ('who', 'valent'),\n",
       " ('moto', 'won'),\n",
       " ('tar', 'p'),\n",
       " ('2007', 'season'),\n",
       " ('s', 'won'),\n",
       " ('lit', 'the'),\n",
       " ('here', 'season'),\n",
       " ('duc', 'valent'),\n",
       " ('at', 'the'),\n",
       " ('defending', 'p'),\n",
       " ('it', 'won'),\n",
       " ('with', 'the'),\n",
       " ('be', 'the'),\n",
       " ('qa', 'the'),\n",
       " (\"'\", 'won'),\n",
       " ('r', 'r'),\n",
       " ('r', 'won'),\n",
       " ('.', 'won'),\n",
       " ('said', 'the'),\n",
       " ('.', 'the'),\n",
       " ('n', 'opening'),\n",
       " ('rider', 'ossi'),\n",
       " ('valent', 'the'),\n",
       " ('caused', 'won'),\n",
       " ('deciding', 'won'),\n",
       " ('australia', 'ossi'),\n",
       " ('moto', 'opening'),\n",
       " ('to', 'the'),\n",
       " ('duc', 'the'),\n",
       " ('sun', 'the'),\n",
       " ('australia', 'ino'),\n",
       " ('the', 'valent'),\n",
       " ('third', 'season'),\n",
       " ('.', 'opening'),\n",
       " ('champion', 'opening'),\n",
       " ('pole', 'moto'),\n",
       " ('r', 'g'),\n",
       " ('the', 'ossi'),\n",
       " ('valent', 'won'),\n",
       " ('a', 'ossi'),\n",
       " ('rain', 'won'),\n",
       " ('weather', 'season'),\n",
       " ('swirling', 'the'),\n",
       " ('r', 'ossi'),\n",
       " ('world', 'moto'),\n",
       " ('tar', 'g'),\n",
       " ('on', 'the'),\n",
       " ('the', 'the'),\n",
       " ('and', 'the'),\n",
       " ('il', 'ino'),\n",
       " ('il', 'opening'),\n",
       " ('tar', 'g'),\n",
       " ('to', 'won'),\n",
       " ('un', 'won'),\n",
       " ('the', 'ino'),\n",
       " ('lit', 'opening'),\n",
       " ('australia', 'valent'),\n",
       " ('valent', 'r'),\n",
       " ('stone', 'ossi'),\n",
       " ('to', 'the'),\n",
       " ('p', 'ossi'),\n",
       " ('other', 'the'),\n",
       " ('mon', 'the'),\n",
       " ('for', 'valent'),\n",
       " ('before', 'the'),\n",
       " ('conditions', 'won'),\n",
       " ('n', 'ossi'),\n",
       " ('who', 'ossi'),\n",
       " ('venue', 'won'),\n",
       " ('win', 'valent'),\n",
       " ('.', 'won'),\n",
       " ('n', 'the'),\n",
       " ('third', 'opening'),\n",
       " ('moments', 'the'),\n",
       " ('australia', 'valent'),\n",
       " ('for', 'ossi'),\n",
       " ('r', 'qa'),\n",
       " ('australia', 'ossi'),\n",
       " ('stone', 'r'),\n",
       " ('due', 'won'),\n",
       " ('here', 'valent'),\n",
       " ('on', 'the'),\n",
       " ('case', 'the'),\n",
       " ('stone', 'won'),\n",
       " ('world', 'valent'),\n",
       " ('a', 'ino'),\n",
       " ('successive', 'valent'),\n",
       " ('torrential', 'won'),\n",
       " ('season', 'moto'),\n",
       " ('champion', 'valent'),\n",
       " ('r', 'the'),\n",
       " ('third', 'valent'),\n",
       " ('sun', 'season'),\n",
       " ('defending', 'moto'),\n",
       " ('just', 'the'),\n",
       " ('n', 'valent'),\n",
       " ('tar', 'season'),\n",
       " ('il', 'tar'),\n",
       " ('to', 'won'),\n",
       " ('at', 'won'),\n",
       " ('opening', 'moto'),\n",
       " ('warm', 'moto'),\n",
       " ('at', 'moto'),\n",
       " ('un', 'the'),\n",
       " ('rider', 'ino'),\n",
       " ('rider', 'valent'),\n",
       " ('world', 'season'),\n",
       " ('champion', 'ossi'),\n",
       " ('riders', 'ossi'),\n",
       " ('2007', 'valent'),\n",
       " ('ossi', 'valent'),\n",
       " ('before', 'won'),\n",
       " ('ino', 'qa'),\n",
       " ('with', 'won'),\n",
       " ('was', 'the'),\n",
       " ('champion', 'p'),\n",
       " ('bidding', 'valent'),\n",
       " ('world', 'qa'),\n",
       " ('champion', 'season'),\n",
       " ('ati', 'ossi'),\n",
       " ('los', 'ossi'),\n",
       " ('il', 'season'),\n",
       " ('cancelled', 'season'),\n",
       " ('y', 'ino'),\n",
       " ('win', 'season'),\n",
       " ('champion', 'ossi'),\n",
       " ('lap', 'p'),\n",
       " ('p', 'moto'),\n",
       " ('on', 'the'),\n",
       " ('opening', 'p'),\n",
       " ('officials', 'won'),\n",
       " ('p', 'tar'),\n",
       " ('world', 'opening'),\n",
       " ('defending', 'valent'),\n",
       " ('just', 'won'),\n",
       " ('a', 'won'),\n",
       " ('y', 'valent'),\n",
       " ('lap', 'moto'),\n",
       " ('win', 'opening'),\n",
       " ('ossi', 'moto'),\n",
       " ('.', 'p'),\n",
       " ('on', 'the'),\n",
       " ('g', 'qa'),\n",
       " ('y', 'ossi'),\n",
       " ('a', 'season'),\n",
       " ('a', 'opening'),\n",
       " ('just', 'the'),\n",
       " ('r', 'valent'),\n",
       " ('just', 'won'),\n",
       " ('for', 'ino'),\n",
       " ('tar', 'qa'),\n",
       " ('australia', 'won'),\n",
       " ('on', 'won'),\n",
       " ('case', 'valent'),\n",
       " ('who', 'r'),\n",
       " ('p', 'ossi'),\n",
       " ('day', 'the'),\n",
       " ('ino', 'p'),\n",
       " ('successive', 'ino'),\n",
       " ('il', 'ossi'),\n",
       " ('was', 'ossi'),\n",
       " ('world', 'valent'),\n",
       " ('teams', 'won'),\n",
       " ('defending', 'ossi'),\n",
       " ('up', 'moto'),\n",
       " ('a', 'opening'),\n",
       " ('tar', 'won'),\n",
       " ('by', 'the'),\n",
       " ('moments', 'won'),\n",
       " ('r', 'ino'),\n",
       " ('the', 'ossi'),\n",
       " ('2007', 'opening'),\n",
       " ('was', 'valent'),\n",
       " ('2007', 'ino'),\n",
       " ('third', 'ino'),\n",
       " ('season', 'qa'),\n",
       " ('australia', 'ino'),\n",
       " ('stone', 'the'),\n",
       " ('r', 'season'),\n",
       " ('n', 'won'),\n",
       " ('stone', 'ino'),\n",
       " ('opening', 'tar'),\n",
       " ('race', 'season'),\n",
       " ('this', 'won'),\n",
       " ('up', 'season'),\n",
       " ('duc', 'ino'),\n",
       " ('like', 'the'),\n",
       " ('australia', 'won'),\n",
       " ('world', 'ino'),\n",
       " ('los', 'opening'),\n",
       " ('leaving', 'won'),\n",
       " ('champion', 'ino'),\n",
       " ('champion', 'r'),\n",
       " ('qa', 'won'),\n",
       " ('day', 'moto'),\n",
       " ('.', 'qa'),\n",
       " ('qa', 'g'),\n",
       " ('world', 'p'),\n",
       " ('riders', 'r'),\n",
       " ('the', 'r'),\n",
       " ('tar', 'ossi'),\n",
       " ('leaving', 'the'),\n",
       " ('case', 'ino'),\n",
       " ('los', 'season'),\n",
       " ('this', 'opening'),\n",
       " ('day', 'won'),\n",
       " ('stone', 'valent'),\n",
       " ('world', 'ino'),\n",
       " ('warm', 'opening'),\n",
       " ('was', 'ino'),\n",
       " ('venue', 'season'),\n",
       " ('ossi', 'g'),\n",
       " ('stone', 'won'),\n",
       " ('up', 'p'),\n",
       " ('2007', 'ossi'),\n",
       " ('bidding', 'ossi'),\n",
       " ('defending', 'ino'),\n",
       " ('r', 'p'),\n",
       " ('riders', 'valent'),\n",
       " ('the', 'moto'),\n",
       " ('los', 'moto'),\n",
       " ('a', 'qa'),\n",
       " ('win', 'r'),\n",
       " ('accompanied', 'the'),\n",
       " ('case', 'won'),\n",
       " ('ino', 'g'),\n",
       " ('win', 'p'),\n",
       " ('this', 'moto'),\n",
       " ('ino', 'season'),\n",
       " ('said', 'opening'),\n",
       " ('af', 'moto'),\n",
       " ('valent', 'season'),\n",
       " ('successive', 'ossi'),\n",
       " ('world', 'ossi'),\n",
       " ('before', 'won'),\n",
       " ('lap', 'opening'),\n",
       " ('qa', 'p'),\n",
       " ('position', 'season'),\n",
       " ('a', 'season'),\n",
       " ('frenzy', 'won'),\n",
       " ('s', 'ossi'),\n",
       " ('champion', 'opening'),\n",
       " ('win', 'moto'),\n",
       " ('the', 'tar'),\n",
       " ('tar', 'ino'),\n",
       " ('teams', 'moto'),\n",
       " (\"'\", 'ossi'),\n",
       " ('bidding', 'opening'),\n",
       " ('win', 'ino'),\n",
       " ('win', 'ossi'),\n",
       " ('qa', 'g'),\n",
       " ('day', 'opening'),\n",
       " ('winds', 'won'),\n",
       " ('instead', 'season'),\n",
       " ('ati', 'valent'),\n",
       " ('champion', 'season'),\n",
       " ('tar', 'ino'),\n",
       " ('tar', 'season'),\n",
       " ('sun', 'won'),\n",
       " ('day', 'won'),\n",
       " ('mon', 'won'),\n",
       " ('duc', 'ossi'),\n",
       " ('rain', 'season'),\n",
       " ('on', 'won'),\n",
       " ('race', 'opening'),\n",
       " ('valent', 'qa'),\n",
       " ('champion', 'moto'),\n",
       " ('teams', 'season'),\n",
       " ('accompanied', 'won'),\n",
       " ('stone', 'ossi'),\n",
       " ('qa', 'p'),\n",
       " ('riders', 'ino'),\n",
       " ('be', 'season'),\n",
       " ('cancelled', 'opening'),\n",
       " ('rider', 'r'),\n",
       " ('moto', 'ino'),\n",
       " ('officials', 'season'),\n",
       " ('other', 'ossi'),\n",
       " ('pole', 'ossi'),\n",
       " ('riders', 'season'),\n",
       " ('for', 'opening'),\n",
       " ('day', 'opening'),\n",
       " ('defending', 'g'),\n",
       " ('qa', 'valent'),\n",
       " ('season', 'p'),\n",
       " ('qa', 'valent'),\n",
       " ('desert', 'won'),\n",
       " ('riders', 'p'),\n",
       " ('moto', 'valent'),\n",
       " ('instead', 'opening'),\n",
       " ('venue', 'tar'),\n",
       " ('los', 'qa'),\n",
       " ('af', 'season'),\n",
       " ('swirling', 'won'),\n",
       " ('champion', 'r'),\n",
       " ('bidding', 'ino'),\n",
       " ('p', 'g'),\n",
       " ('rain', 'opening'),\n",
       " ('y', 'won'),\n",
       " ('successive', 'p'),\n",
       " ('a', 'tar'),\n",
       " ('on', 'season'),\n",
       " ('stone', 'the'),\n",
       " ('.', 'moto'),\n",
       " ('case', 'ossi'),\n",
       " ('r', 'the'),\n",
       " ('australia', 'r'),\n",
       " ('was', 'r'),\n",
       " ('a', 'r'),\n",
       " ('mon', 'moto'),\n",
       " ('on', 'moto'),\n",
       " ('pole', 'opening'),\n",
       " ('position', 'moto'),\n",
       " ('r', 'opening'),\n",
       " ('.', 'tar'),\n",
       " ('s', 'valent'),\n",
       " ('riders', 'opening'),\n",
       " ('ati', 'won'),\n",
       " ('il', 'valent'),\n",
       " ('il', 'p'),\n",
       " ('qa', 'ino'),\n",
       " ('moto', 'ossi'),\n",
       " ('for', 'season'),\n",
       " ('a', 'ino'),\n",
       " ('race', 'p'),\n",
       " ('third', 'ossi'),\n",
       " ('n', 'r'),\n",
       " ('world', 'ossi'),\n",
       " ('for', 'r'),\n",
       " ('this', 'season'),\n",
       " ('by', 'won'),\n",
       " (\"'\", 'valent'),\n",
       " ('world', 'g'),\n",
       " ('here', 'moto'),\n",
       " ('and', 'the'),\n",
       " ('stone', 'ino'),\n",
       " ('opening', 'g'),\n",
       " ('a', 'the'),\n",
       " ('mon', 'season'),\n",
       " ('day', 'season'),\n",
       " ('monsoon', 'season'),\n",
       " ('ossi', 'tar'),\n",
       " ('.', 'ossi'),\n",
       " ('was', 'season'),\n",
       " ('af', 'p'),\n",
       " ('day', 'p'),\n",
       " ('defending', 'qa'),\n",
       " ('ossi', 'opening'),\n",
       " ('los', 'r'),\n",
       " ('australia', 'r'),\n",
       " ('season', 'tar'),\n",
       " ('in', 'the'),\n",
       " ('like', 'won'),\n",
       " ('world', 'moto'),\n",
       " ('here', 'ossi'),\n",
       " ('qa', 'r'),\n",
       " ('qa', 'ossi'),\n",
       " ('be', 'moto'),\n",
       " ('pole', 'valent'),\n",
       " ('lead', 'season'),\n",
       " ('s', 'ossi'),\n",
       " ('here', 'p'),\n",
       " ('af', 'opening'),\n",
       " ('venue', 'p'),\n",
       " ('champion', 'qa'),\n",
       " ('valent', 'moto'),\n",
       " ('af', 'qa'),\n",
       " ('successive', 'r'),\n",
       " ('win', 'g'),\n",
       " ('p', 'opening'),\n",
       " ('the', 'moto'),\n",
       " ('tar', 'ossi'),\n",
       " ('champion', 'g'),\n",
       " ('r', 'tar'),\n",
       " ('and', 'moto'),\n",
       " ('.', 'p'),\n",
       " ('day', 'season'),\n",
       " ('on', 'opening'),\n",
       " ('australia', 'opening'),\n",
       " ('il', 'moto'),\n",
       " ('p', 'season'),\n",
       " ('to', 'moto'),\n",
       " ('monsoon', 'won'),\n",
       " ('and', 'r'),\n",
       " ('up', 'g'),\n",
       " ('australia', 'moto'),\n",
       " ('valent', 'opening'),\n",
       " ('ossi', 'season'),\n",
       " (\"'\", 'ossi'),\n",
       " (\"'\", 'ino'),\n",
       " ('lucky', 'ossi'),\n",
       " ('weather', 'moto'),\n",
       " ('r', 'tar'),\n",
       " ('bidding', 'r'),\n",
       " ('the', 'p'),\n",
       " ('af', 'g'),\n",
       " ('pole', 'season'),\n",
       " ('champion', 'tar'),\n",
       " ('.', 'season'),\n",
       " ('weather', 'valent'),\n",
       " ('.', 'g'),\n",
       " ('il', 'qa'),\n",
       " ('qa', 'ino'),\n",
       " ('the', 'moto'),\n",
       " ('weather', 'opening'),\n",
       " ('a', 'ossi'),\n",
       " ('season', 'valent'),\n",
       " ('moto', 'r'),\n",
       " ('like', 'opening'),\n",
       " ('here', 'ino'),\n",
       " ('officials', 'moto'),\n",
       " ('in', 'won'),\n",
       " ('pole', 'r'),\n",
       " ('lucky', 'valent'),\n",
       " ('was', 'opening'),\n",
       " ('qa', 'ossi'),\n",
       " ('desert', 'moto'),\n",
       " ('other', 'valent'),\n",
       " ('riders', 'g'),\n",
       " ('just', 'ossi'),\n",
       " ('duc', 'won'),\n",
       " ('here', 'r'),\n",
       " ('g', 'ossi'),\n",
       " ('on', 'season'),\n",
       " ('before', 'opening'),\n",
       " ('teams', 'opening'),\n",
       " ('race', 'ossi'),\n",
       " ('position', 'opening'),\n",
       " ('lap', 'season'),\n",
       " ('weather', 'ossi'),\n",
       " ('ati', 'moto'),\n",
       " ('successive', 'moto'),\n",
       " ('defending', 'r'),\n",
       " ('rider', 'opening'),\n",
       " ('2007', 'r'),\n",
       " ('los', 'tar'),\n",
       " ('af', 'ossi'),\n",
       " ('opening', 'qa'),\n",
       " ('p', 'qa'),\n",
       " ('stone', 'r'),\n",
       " ('bidding', 'season'),\n",
       " ('a', 'won'),\n",
       " ('race', 'g'),\n",
       " ('y', 'r'),\n",
       " ('riders', 'qa'),\n",
       " ('a', 'moto'),\n",
       " ('a', 'p'),\n",
       " ('at', 'opening'),\n",
       " ('australia', 'season'),\n",
       " ('warm', 'p'),\n",
       " ('the', 'ossi'),\n",
       " ('torrential', 'season'),\n",
       " ('caused', 'opening'),\n",
       " ('s', 'ino'),\n",
       " ('the', 'season'),\n",
       " ('season', 'g'),\n",
       " ('cancelled', 'p'),\n",
       " ('day', 'g'),\n",
       " ('flood', 'won'),\n",
       " ('said', 'valent'),\n",
       " ('who', 'opening'),\n",
       " ('af', 'r'),\n",
       " ('instead', 'moto'),\n",
       " ('at', 'season'),\n",
       " ('conditions', 'season'),\n",
       " ('world', 'tar'),\n",
       " ('.', 'r'),\n",
       " ('.', 'opening'),\n",
       " ('a', 'valent'),\n",
       " ('the', 'qa'),\n",
       " ('qa', 'r'),\n",
       " ('to', 'moto'),\n",
       " ('third', 'r'),\n",
       " ('torrential', 'opening'),\n",
       " ('sun', 'opening'),\n",
       " ('australia', 'opening'),\n",
       " ('win', 'qa'),\n",
       " ('caused', 'season'),\n",
       " ('be', 'p'),\n",
       " ('officials', 'opening'),\n",
       " ('teams', 'valent'),\n",
       " ('flood', 'opening'),\n",
       " ('lucky', 'opening'),\n",
       " ('duc', 'qa'),\n",
       " ('rider', 'season'),\n",
       " ('desert', 'season'),\n",
       " ('to', 'moto'),\n",
       " ('ossi', 'qa'),\n",
       " ('other', 'ino'),\n",
       " ('the', 'season'),\n",
       " ('australia', 'season'),\n",
       " ('world', 'r'),\n",
       " ('a', 'moto'),\n",
       " ('tar', 'r'),\n",
       " ('g', 'ino'),\n",
       " ('desert', 'ossi'),\n",
       " ('.', 'season'),\n",
       " ('australia', 'qa'),\n",
       " ('on', 'moto'),\n",
       " ('.', 'valent'),\n",
       " ('race', 'ino'),\n",
       " ('the', 'valent'),\n",
       " ('rain', 'qa'),\n",
       " ('world', 'r'),\n",
       " ('the', 'moto'),\n",
       " ('warm', 'g'),\n",
       " (\"'\", 'valent'),\n",
       " ('un', 'valent'),\n",
       " ('who', 'season'),\n",
       " ('cancelled', 'moto'),\n",
       " ('s', 'moto'),\n",
       " ('pole', 'p'),\n",
       " ('up', 'ossi'),\n",
       " ('successive', 'g'),\n",
       " ('lit', 'won'),\n",
       " ('desert', 'tar'),\n",
       " ('.', 'p'),\n",
       " ('un', 'ossi'),\n",
       " ('said', 'ossi'),\n",
       " ('the', 'opening'),\n",
       " ('opening', 'ossi'),\n",
       " ('g', 'r'),\n",
       " ('venue', 'qa'),\n",
       " ('position', 'ossi'),\n",
       " ('to', 'ossi'),\n",
       " ('valent', 'tar'),\n",
       " ('lucky', 'ino'),\n",
       " ('tar', 'valent'),\n",
       " ('this', 'ossi'),\n",
       " ('this', 'tar'),\n",
       " ('duc', 'r'),\n",
       " ('ati', 'tar'),\n",
       " ('r', 'p'),\n",
       " ('2007', 'p'),\n",
       " ('season', 'ino'),\n",
       " ('tar', 'valent'),\n",
       " ('teams', 'ossi'),\n",
       " ('race', 'valent'),\n",
       " ('desert', 'qa'),\n",
       " ('case', 'r'),\n",
       " ('r', 'moto'),\n",
       " ('on', 'ossi'),\n",
       " ('the', 'opening'),\n",
       " ('.', 'qa'),\n",
       " ('weather', 'ino'),\n",
       " ('the', 'r'),\n",
       " ('weather', 'p'),\n",
       " ('australia', 'moto'),\n",
       " ('the', 'season'),\n",
       " ('af', 'valent'),\n",
       " ('to', 'p'),\n",
       " ('on', 'moto'),\n",
       " ('australia', 'p'),\n",
       " ('lap', 'g'),\n",
       " ('the', 'opening'),\n",
       " ('deciding', 'opening'),\n",
       " ('instead', 'ossi'),\n",
       " ('venue', 'ossi'),\n",
       " ('pole', 'ino'),\n",
       " ('other', 'r'),\n",
       " ('it', 'ossi'),\n",
       " ('it', 'season'),\n",
       " ('world', 'qa'),\n",
       " ('for', 'moto'),\n",
       " ('here', 'qa'),\n",
       " ('race', 'tar'),\n",
       " ('desert', 'opening'),\n",
       " ('lap', 'ino'),\n",
       " ('.', 'moto'),\n",
       " ('ati', 'r'),\n",
       " ('rain', 'p'),\n",
       " ('mon', 'qa'),\n",
       " ('monsoon', 'ossi'),\n",
       " ('.', 'ino'),\n",
       " (\"'\", 'ino'),\n",
       " ('opening', 'ino'),\n",
       " ('to', 'season'),\n",
       " ('and', 'won'),\n",
       " ('deciding', 'season'),\n",
       " ('mon', 'p'),\n",
       " ('instead', 'tar'),\n",
       " ('flood', 'season'),\n",
       " ('monsoon', 'moto'),\n",
       " ('conditions', 'opening'),\n",
       " (\"'\", 'moto'),\n",
       " ('riders', 'tar'),\n",
       " ('ati', 'opening'),\n",
       " ('ati', 'p'),\n",
       " ('r', 'moto'),\n",
       " ('los', 'p'),\n",
       " ('day', 'p'),\n",
       " ('leaving', 'opening'),\n",
       " ('australia', 'tar'),\n",
       " ('warm', 'ossi'),\n",
       " ('r', 'opening'),\n",
       " ('was', 'p'),\n",
       " ('for', 'p'),\n",
       " ('here', 'tar'),\n",
       " ('the', 'ossi'),\n",
       " ('be', 'opening'),\n",
       " ('race', 'r'),\n",
       " ('venue', 'g'),\n",
       " ('.', 'ossi'),\n",
       " ('winds', 'opening'),\n",
       " (\"'\", 'opening'),\n",
       " ('position', 'p'),\n",
       " ('mon', 'opening'),\n",
       " ('mon', 'g'),\n",
       " ('day', 'tar'),\n",
       " ('lead', 'opening'),\n",
       " ('australia', 'qa'),\n",
       " ('duc', 'moto'),\n",
       " ('los', 'g'),\n",
       " ('p', 'r'),\n",
       " ('rain', 'moto'),\n",
       " ('frenzy', 'season'),\n",
       " ('and', 'valent'),\n",
       " ('the', 'valent'),\n",
       " ('other', 'moto'),\n",
       " ('champion', 'p'),\n",
       " ('here', 'g'),\n",
       " ('il', 'r'),\n",
       " ('desert', 'valent'),\n",
       " ('desert', 'ino'),\n",
       " ('before', 'season'),\n",
       " ('y', 'qa'),\n",
       " ('valent', 'p'),\n",
       " ('with', 'season'),\n",
       " ('mon', 'valent'),\n",
       " ('pole', 'g'),\n",
       " ('the', 'p'),\n",
       " ('.', 'g'),\n",
       " ('it', 'opening'),\n",
       " ('lucky', 'season'),\n",
       " ('teams', 'ino'),\n",
       " ('instead', 'p'),\n",
       " ('pole', 'qa'),\n",
       " ('lead', 'valent'),\n",
       " ('and', 'ino'),\n",
       " ('up', 'tar'),\n",
       " (\"'\", 'season'),\n",
       " ('with', 'ossi'),\n",
       " ('weather', 'r'),\n",
       " ('who', 'p'),\n",
       " ('race', 'qa'),\n",
       " ...]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn = format_attention(attention, tokens)  \n",
    "tokens = format_special_chars(tokens)\n",
    "sentence_b_start = token_type_ids[0].tolist().index(1)\n",
    "slice_a = slice(0, sentence_b_start)\n",
    "slice_b = slice(sentence_b_start, len(tokens))\n",
    "attn_data = attn[:, :, slice_a, slice_b]\n",
    "sentence_a_tokens = tokens[slice_a]\n",
    "sentence_b_tokens = tokens[slice_b]\n",
    "pair = pair_match(sentence_a_tokens, sentence_b_tokens, attn_data=attn_data)\n",
    "pair = sorted(pair, key=lambda pair: pair[2], reverse=True)\n",
    "pair = pair_without_score(pair)\n",
    "pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLNetForMultiSequenceClassification(XLNetPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = 3\n",
    "        self.num_labels_3way = 3\n",
    "        self.num_labels_multi = 5\n",
    "        \n",
    "        self.transformer = XLNetModel(config)\n",
    "        self.sequence_summary = SequenceSummary(config)\n",
    "        self.logits_proj_3way = nn.Linear(config.d_model, self.num_labels_3way)\n",
    "        self.logits_proj_multi = nn.Linear(config.d_model, self.num_labels_multi)\n",
    "        \n",
    "        self.weights_3way = [1, 1.5, 3]\n",
    "        self.weights_multi = [4, 2, 4, 2, 2]\n",
    "        self.class_weights_3way = torch.FloatTensor(self.weights_3way).to(device)\n",
    "        self.class_weights_multi = torch.FloatTensor(self.weights_multi).to(device)\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, mems=None, perm_mask=None, target_mapping=None,\n",
    "                token_type_ids=None, input_mask=None, head_mask=None, labels=None, inputs_embeds=None):\n",
    "        transformer_outputs = self.transformer(input_ids,\n",
    "                                               attention_mask=attention_mask,\n",
    "                                               mems=mems,\n",
    "                                               perm_mask=perm_mask,\n",
    "                                               target_mapping=target_mapping,\n",
    "                                               token_type_ids=token_type_ids,\n",
    "                                               input_mask=input_mask, \n",
    "                                               head_mask=head_mask,\n",
    "                                               inputs_embeds=inputs_embeds)\n",
    "\n",
    "        output = transformer_outputs[0]\n",
    "        output = self.sequence_summary(output)\n",
    "        \n",
    "        if labels is None:\n",
    "            logits = self.logits_proj_3way(output)\n",
    "            outputs = (logits,) + transformer_outputs[1:]\n",
    "\n",
    "        if labels is not None:\n",
    "            task_check = 0\n",
    "        \n",
    "            if labels.size() == torch.Size([1]):\n",
    "                logits_3way = self.logits_proj_3way(output)\n",
    "                outputs = (logits_3way,) + transformer_outputs[1:]\n",
    "                task_check = 1\n",
    "            else:\n",
    "                logits_multi = self.logits_proj_multi(output)\n",
    "                outputs = (logits_multi,) + transformer_outputs[1:]\n",
    "\n",
    "            if task_check:\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits_3way.view(-1, self.num_labels_3way), labels.view(-1)).to(device)\n",
    "            else:\n",
    "                loss_fct = BCEWithLogitsLoss(pos_weight=self.class_weights_multi)\n",
    "                loss = loss_fct(logits_multi.view(-1, self.num_labels_multi), labels).to(device)\n",
    "            outputs = (loss,) + outputs\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = torch.load('test.pkl',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_single = torch.load('acc_0.5_complete.pkl',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataset import ConcatDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def format_special_chars(tokens):\n",
    "    return [t.replace('Ġ', ' ').replace('▁', ' ').replace('</w>', '').replace(' ', '') for t in tokens]\n",
    "\n",
    "def format_attention(attention, tokens):\n",
    "    \"\"\" Set special token <sep>, <cls> attention to zero and format the attention \"\"\"\n",
    "    # set special token's attention to zero\n",
    "    for i, t in enumerate(tokens):\n",
    "        if t in (\"<sep>\", \"<cls>\"):\n",
    "            for layer_attn in attention:\n",
    "                layer_attn[0, :, i, :] = 0\n",
    "                layer_attn[0, :, :, i] = 0\n",
    "    squeezed = []\n",
    "    for layer_attention in attention:\n",
    "        # 1 x num_heads x seq_len x seq_len\n",
    "        if len(layer_attention.shape) != 4:\n",
    "            raise ValueError(\"Wrong attention length, attention length must be 4\")\n",
    "        squeezed.append(layer_attention.squeeze(0))\n",
    "    # num_layers x num_heads x seq_len x seq_len\n",
    "    return torch.stack(squeezed)\n",
    "\n",
    "def look_score(attn_data, index_a, index_b):\n",
    "    \"\"\" Look pair attention score in layers, head \"\"\"\n",
    "    score = 0.\n",
    "    for layer in attn_data:\n",
    "        for head in layer:\n",
    "            score_individual = head[index_a][index_b].tolist()\n",
    "            score += score_individual\n",
    "    return round(score, 3)\n",
    "\n",
    "def pair_match(sentence_a_tokens, sentence_b_tokens, attn_data=None):\n",
    "    \"\"\" Matching each token in sentence_a and sentence_b and making pairs \"\"\"\n",
    "    pairs = []\n",
    "    for index_a in range(len(sentence_a_tokens)):\n",
    "        for index_b in range(len(sentence_b_tokens)):\n",
    "            if attn_data is not None:\n",
    "                score = look_score(attn_data, index_a, index_b)\n",
    "                pair = (sentence_a_tokens[index_a], sentence_b_tokens[index_b], score)\n",
    "                # filter the special token\n",
    "                if score != 0:\n",
    "                    pairs.append(pair)\n",
    "            else:\n",
    "                # for evaluation pairs\n",
    "                pair = (sentence_a_tokens[index_a], sentence_b_tokens[index_b])\n",
    "                pairs.append(pair)\n",
    "    return pairs\n",
    "\n",
    "def pair_without_score(pair):\n",
    "    \"\"\" Return pairs without score \"\"\"\n",
    "    pairs = []\n",
    "    for token_a, token_b, score in pair:\n",
    "        if token_a != '' and token_b != '':\n",
    "            pair = (token_a, token_b)\n",
    "            pairs.append(pair)\n",
    "    return pairs\n",
    "\n",
    "def MRR_calculate(pair_truth, pair_all):\n",
    "    final_score = 0.\n",
    "    for query in pair_truth:\n",
    "        for response in range(len(pair_all)):\n",
    "            if pair_all[response] == query:\n",
    "                score = 1/(response+1)\n",
    "                final_score += score\n",
    "    final_score = final_score/len(pair_truth)\n",
    "    return final_score\n",
    "\n",
    "def MRR_mean(pair_truth, pair_all, top_k, times):\n",
    "    \"\"\" Choose k tokens from tokens list for calculating MRR\"\"\"\n",
    "    filtered = random.choices(pair_truth, k=top_k)\n",
    "    final = 0.\n",
    "    for i in range(times):\n",
    "        score = MRR_calculate(filtered, pair_all)\n",
    "        final += score\n",
    "    final = final/times\n",
    "    return final\n",
    "\n",
    "def explainability_compare(model, tokenizer, sentence_a, sentence_b, test_sentence_a):\n",
    "    \"\"\" Evaluating MRR between model and attention span\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True)\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    input_ids.squeeze()\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze().tolist())\n",
    "    token_type_ids = inputs['token_type_ids'].to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n",
    "    \n",
    "    attn = format_attention(attention, tokens)  \n",
    "    tokens = format_special_chars(tokens)\n",
    "    sentence_b_start = token_type_ids[0].tolist().index(1)\n",
    "    slice_a = slice(0, sentence_b_start)\n",
    "    slice_b = slice(sentence_b_start, len(tokens))\n",
    "    attn_data = attn[:, :, slice_a, slice_b]\n",
    "    sentence_a_tokens = tokens[slice_a]\n",
    "    sentence_b_tokens = tokens[slice_b]\n",
    "    pair = pair_match(sentence_a_tokens, sentence_b_tokens, attn_data=attn_data)\n",
    "    pair = sorted(pair, key=lambda pair: pair[2], reverse=True)\n",
    "    pair = pair_without_score(pair)\n",
    "    \n",
    "    test_inputs = tokenizer.encode_plus(test_sentence_a, sentence_b, return_tensors='pt', add_special_tokens=False)\n",
    "    test_input_ids = test_inputs['input_ids']\n",
    "    test_input_ids.squeeze()\n",
    "    test_tokens = tokenizer.convert_ids_to_tokens(test_input_ids.squeeze().tolist())\n",
    "    test_token_type_ids = test_inputs['token_type_ids']\n",
    "    test_tokens = format_special_chars(test_tokens)\n",
    "    test_sentence_b_start = test_token_type_ids[0].tolist().index(1)\n",
    "    test_slice_a = slice(0, test_sentence_b_start)\n",
    "    test_slice_b = slice(test_sentence_b_start, len(test_tokens))\n",
    "    test_sentence_a_tokens = test_tokens[test_slice_a]\n",
    "    test_sentence_b_tokens = test_tokens[test_slice_b]\n",
    "    test_pair = pair_match(test_sentence_a_tokens, test_sentence_b_tokens, attn_data=None)\n",
    "\n",
    "    return MRR_calculate(test_pair, pair), len(test_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = ET.parse('RTE5_test_AttnSpan.xml').getroot()\n",
    "text = []\n",
    "hypothesis = []\n",
    "entailment = []\n",
    "attention = []\n",
    "\n",
    "label_mapping = {'ENTAILMENT': 0, 'UNKNOWN': 1, 'CONTRADICTION': 2}\n",
    "\n",
    "replacement = {\"hasn't\": 'has not', \n",
    "               \"couldn't\": 'could not', \n",
    "               \"wasn't\": 'was not', \n",
    "               \"weren't\": 'were not', \n",
    "               \"doesn't\": 'does not',\n",
    "               \"don't\": 'do not',\n",
    "               '\"': '',\n",
    "              }\n",
    "\n",
    "for type_tag in root.findall('pair'):\n",
    "    \n",
    "    e = type_tag.get('entailment')\n",
    "    t = type_tag.find('t').text\n",
    "    t = t.lower()\n",
    "    for word, rep in replacement.items():\n",
    "        t = t.replace(word.lower(), rep)\n",
    "    t = re.sub(r\"([\\(\\)\\[\\]\\{\\}!-])\", \"\", t)\n",
    "    \n",
    "    h = type_tag.find('h').text\n",
    "    h = h.lower()\n",
    "    for word, rep in replacement.items():\n",
    "        h = h.replace(word.lower(), rep)\n",
    "    h = re.sub(r\"([\\(\\)\\[\\]\\{\\}!-])\", \"\", h)\n",
    "    \n",
    "    a = type_tag.find('a').text\n",
    "    a = a.lower()\n",
    "    for word, rep in replacement.items():\n",
    "        h = h.replace(word.lower(), rep)\n",
    "    a = re.sub(r\"([\\(\\)\\[\\]\\{\\}!-])\", \"\", a)\n",
    "    \n",
    "    \n",
    "    text.append(t)\n",
    "    hypothesis.append(h)\n",
    "    attention.append(a)\n",
    "    entailment.append(label_mapping[e])\n",
    "    \n",
    "df_test = pd.DataFrame((zip(text, hypothesis, attention, entailment)), columns=['text_a', 'text_b', 'eval_text','label'])\n",
    "df_test.to_csv(\"test_2.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(data):\n",
    "    \n",
    "    # Total\n",
    "    total,\n",
    "    total_MRR,\n",
    "    total_acc,\n",
    "    total_mean_len,\n",
    "    # Entail\n",
    "    entail_total,\n",
    "    entail_acc,\n",
    "    entail_mean_len,\n",
    "    entail_MRR,\n",
    "    entail_correct,\n",
    "    entail_correct_mean_len,\n",
    "    entail_MRR_c,\n",
    "    entail_incorrect,\n",
    "    entail_incorrect_mean_len,\n",
    "    entail_MRR_inc,\n",
    "    # Neutral\n",
    "    neutral_total,\n",
    "    neutral_acc,\n",
    "    neutral_mean_len,\n",
    "    neutral_MRR,\n",
    "    neutral_correct,\n",
    "    neutral_correct_mean_len,\n",
    "    neutral_MRR_c,\n",
    "    neutral_incorrect,\n",
    "    neutral_incorrect_mean_len,\n",
    "    neutral_MRR_inc,\n",
    "    # Contradict\n",
    "    contradict_total,\n",
    "    contradict_acc,\n",
    "    contradict_mean_len,\n",
    "    contradict_MRR,\n",
    "    contradict_correct,\n",
    "    contradict_correct_mean_len,\n",
    "    contradict_MRR_c,\n",
    "    contradict_incorrect,\n",
    "    contradict_incorrect_mean_len,\n",
    "    contradict_MRR_inc = (data[key] for key in data)\n",
    "      \n",
    "    print(\"\"\"\n",
    "    ------------------------------------------------------------------------------------------------------\n",
    "    |       Total: %g      |        Acc: %g       |        MRR: %g        |      Mean_length: %g       |\n",
    "    ------------------------------------------------------------------------------------------------------\n",
    "    |            ENTAILMENT            |             NEUTRAL           |        CONTRADICTION            |\n",
    "    ------------------------------------------------------------------------------------------------------\n",
    "    |\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf8537db3154a0a9137292d97f8b61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=230, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-37d346353872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature-extraction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Leila is a little pig'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline('feature-extraction')\n",
    "a = nlp('Leila is a little pig')\n",
    "len(a[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
