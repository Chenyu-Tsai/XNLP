{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm, trange\n",
    "from XLNet import XLNetForMultiSequenceClassification\n",
    "\n",
    "from transformers import (\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    XLNetTokenizer,\n",
    "    XLNetConfig,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from processor import SnliProcessor as processors\n",
    "from processor import convert_examples_to_features\n",
    "from metrics import snli_compute_metrics as compute_metrics\n",
    "from statsmodels.sandbox.stats.runs import mcnemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = processors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = processor.get_dev_examples('data/')\n",
    "features = convert_examples_to_features(\n",
    "    examples,\n",
    "    tokenizer,\n",
    "    max_length=64,\n",
    ")\n",
    "all_inputs_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
    "all_labels = torch.tensor([int(f.label) for f in features], dtype=torch.long)\n",
    "eval_dataset = TensorDataset(all_inputs_ids, all_attention_mask, all_token_type_ids, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalute(eval_dataset, model, tokenizer, prefix=\"\"): \n",
    "    eval_task_names = (\"snli\",)\n",
    "    eval_outputs_dirs = ('data/')\n",
    "\n",
    "    pred = []\n",
    "    label = []\n",
    "    for eval_task, eval_output_dir in zip(eval_task_names, eval_outputs_dirs):\n",
    "\n",
    "        eval_batch_size = 16\n",
    "        eval_sampler = SequentialSampler(eval_dataset)\n",
    "        eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=eval_batch_size)\n",
    "\n",
    "        # Eval!\n",
    "        logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "        logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "        logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "        eval_loss = 0.0\n",
    "        nb_eval_steps = 0\n",
    "        preds = None\n",
    "        out_label_ids = None\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\", position=0, leave=True, ncols=100):\n",
    "            model.eval()\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                inputs = {'input_ids':      batch[0],\n",
    "                          'attention_mask': batch[1],\n",
    "                          'token_type_ids': batch[2],\n",
    "                          'labels':         batch[3],\n",
    "                          'task':                 0,\n",
    "                          }\n",
    "                outputs = model(**inputs)\n",
    "                tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "                eval_loss += tmp_eval_loss.mean().item()\n",
    "            nb_eval_steps += 1\n",
    "            if preds is None:\n",
    "                preds = logits.detach().cpu().numpy()\n",
    "                out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "                out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "\n",
    "        pred.append(preds)\n",
    "        label.append(out_label_ids)\n",
    "                \n",
    "    return pred, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|                                                           | 0/616 [00:00<?, ?it/s]C:\\Users\\cheny\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "Evaluating: 100%|█████████████████████████████████████████████████| 616/616 [00:45<00:00, 13.54it/s]\n",
      "Evaluating: 100%|█████████████████████████████████████████████████| 616/616 [00:45<00:00, 13.49it/s]\n"
     ]
    }
   ],
   "source": [
    "model = XLNetForMultiSequenceClassification.from_pretrained('models/SNLI-1%/1t821-1')\n",
    "tokenizer = XLNetTokenizer.from_pretrained('models/SNLI-1%/1t827')\n",
    "model.to(device)\n",
    "pred_1_1t, label = evalute(eval_dataset, model, tokenizer, prefix=\"\")\n",
    "model = XLNetForMultiSequenceClassification.from_pretrained('models/SNLI-1%/2t829-1')\n",
    "tokenizer = XLNetTokenizer.from_pretrained('models/SNLI-1%/2t833')\n",
    "model.to(device)\n",
    "pred_1_2t, label = evalute(eval_dataset, model, tokenizer, prefix=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_accuracy(preds, labels):\n",
    "    preds = np.asarray(preds)\n",
    "    labels = np.asarray(labels)\n",
    "    assert len(preds) == len(labels)\n",
    "    return (preds == labels).mean()\n",
    "def convert_bi(preds, labels):\n",
    "    preds = np.asarray(preds).flatten()\n",
    "    labels = np.asarray(labels).flatten()\n",
    "\n",
    "    return preds == labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8131107491856677"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_accuracy(pred_1_1t, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8189128664495114"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_accuracy(pred_1_2t, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1t = convert_bi(pred_1_1t, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2t = convert_bi(pred_1_2t, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.7216494845360826, 0.05371128596527664)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcnemar(result_1t, result_2t, exact=False, correction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
